{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "N76jvKLK3FWZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ipywidgets as widgets \n",
    "from IPython.display import display \n",
    "import pylab\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "JfDufDYP3FWc"
   },
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "import networkx as nx\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JaQYSxYt3FWc",
    "outputId": "5b1ec59b-4a71-4c20-ce92-f73d4b11e348"
   },
   "outputs": [],
   "source": [
    "df_arsenic_prelim = pd.read_csv (r'C:\\Users\\Ryan\\Desktop\\Research\\Data\\Prelim-data\\as.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dLQUv3sU3FWd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SiteID</th>\n",
       "      <th>As</th>\n",
       "      <th>X_Albers</th>\n",
       "      <th>Y_Albers</th>\n",
       "      <th>WellDepth</th>\n",
       "      <th>AvgAnnualN_CAFO_1992_97</th>\n",
       "      <th>AvgAnnualN_Fert_1992_2001</th>\n",
       "      <th>AWC</th>\n",
       "      <th>AWS25</th>\n",
       "      <th>BFI</th>\n",
       "      <th>...</th>\n",
       "      <th>Transmiss</th>\n",
       "      <th>TWI</th>\n",
       "      <th>VRT</th>\n",
       "      <th>VWC</th>\n",
       "      <th>YngWtrMeanAge</th>\n",
       "      <th>YngWtrMeanAge_VertMean</th>\n",
       "      <th>DTW</th>\n",
       "      <th>Data</th>\n",
       "      <th>as10</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>924000.0</td>\n",
       "      <td>2006000.0</td>\n",
       "      <td>105.912831</td>\n",
       "      <td>16.678065</td>\n",
       "      <td>48.483771</td>\n",
       "      <td>0.141277</td>\n",
       "      <td>5.384314</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>143.362904</td>\n",
       "      <td>9.902970</td>\n",
       "      <td>5.956547</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>23.158235</td>\n",
       "      <td>17.689265</td>\n",
       "      <td>3.082386</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>892000.0</td>\n",
       "      <td>2080000.0</td>\n",
       "      <td>54.861323</td>\n",
       "      <td>7.688502</td>\n",
       "      <td>50.638261</td>\n",
       "      <td>0.217775</td>\n",
       "      <td>7.311919</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>137.152244</td>\n",
       "      <td>9.067347</td>\n",
       "      <td>4.196766</td>\n",
       "      <td>0.343552</td>\n",
       "      <td>22.015855</td>\n",
       "      <td>17.739371</td>\n",
       "      <td>3.076582</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>886000.0</td>\n",
       "      <td>2066000.0</td>\n",
       "      <td>34.745504</td>\n",
       "      <td>6.245885</td>\n",
       "      <td>43.503552</td>\n",
       "      <td>0.140200</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>121.646066</td>\n",
       "      <td>11.470297</td>\n",
       "      <td>17.558480</td>\n",
       "      <td>0.270166</td>\n",
       "      <td>17.762669</td>\n",
       "      <td>15.950136</td>\n",
       "      <td>5.645093</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>898000.0</td>\n",
       "      <td>2076000.0</td>\n",
       "      <td>59.737885</td>\n",
       "      <td>4.900404</td>\n",
       "      <td>34.132068</td>\n",
       "      <td>0.154753</td>\n",
       "      <td>5.318469</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>298.232568</td>\n",
       "      <td>9.815662</td>\n",
       "      <td>1.231952</td>\n",
       "      <td>0.328985</td>\n",
       "      <td>27.709500</td>\n",
       "      <td>17.589893</td>\n",
       "      <td>1.044807</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>896000.0</td>\n",
       "      <td>2062000.0</td>\n",
       "      <td>45.717769</td>\n",
       "      <td>6.511748</td>\n",
       "      <td>45.355325</td>\n",
       "      <td>0.140200</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97.123320</td>\n",
       "      <td>9.435353</td>\n",
       "      <td>21.539828</td>\n",
       "      <td>0.268193</td>\n",
       "      <td>19.238581</td>\n",
       "      <td>14.557619</td>\n",
       "      <td>8.535328</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>610000.0</td>\n",
       "      <td>2484000.0</td>\n",
       "      <td>19.506248</td>\n",
       "      <td>8.030330</td>\n",
       "      <td>10.843744</td>\n",
       "      <td>0.159466</td>\n",
       "      <td>4.090000</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>115.224598</td>\n",
       "      <td>13.790910</td>\n",
       "      <td>0.416030</td>\n",
       "      <td>0.344196</td>\n",
       "      <td>8.765928</td>\n",
       "      <td>16.686542</td>\n",
       "      <td>0.188501</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>6.0</td>\n",
       "      <td>616000.0</td>\n",
       "      <td>2526000.0</td>\n",
       "      <td>24.992380</td>\n",
       "      <td>0.158934</td>\n",
       "      <td>0.199489</td>\n",
       "      <td>0.126106</td>\n",
       "      <td>4.030000</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.882361</td>\n",
       "      <td>11.154347</td>\n",
       "      <td>1.048951</td>\n",
       "      <td>0.253424</td>\n",
       "      <td>15.627269</td>\n",
       "      <td>11.281490</td>\n",
       "      <td>1.518130</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>602000.0</td>\n",
       "      <td>2586000.0</td>\n",
       "      <td>26.211521</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.015434</td>\n",
       "      <td>0.126106</td>\n",
       "      <td>4.030000</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>59.112810</td>\n",
       "      <td>13.113131</td>\n",
       "      <td>0.520421</td>\n",
       "      <td>0.280687</td>\n",
       "      <td>21.815356</td>\n",
       "      <td>15.832110</td>\n",
       "      <td>0.643534</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>10001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>668000.0</td>\n",
       "      <td>2620000.0</td>\n",
       "      <td>12.496190</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>0.058744</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>59.639661</td>\n",
       "      <td>12.550000</td>\n",
       "      <td>0.098656</td>\n",
       "      <td>0.367925</td>\n",
       "      <td>5.079691</td>\n",
       "      <td>14.141643</td>\n",
       "      <td>0.114506</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>6528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10002 rows Ã— 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SiteID    As  X_Albers   Y_Albers   WellDepth  AvgAnnualN_CAFO_1992_97  \\\n",
       "0           1   6.0  924000.0  2006000.0  105.912831                16.678065   \n",
       "1           2   1.0  892000.0  2080000.0   54.861323                 7.688502   \n",
       "2           3  13.0  886000.0  2066000.0   34.745504                 6.245885   \n",
       "3           4   1.0  898000.0  2076000.0   59.737885                 4.900404   \n",
       "4           5   2.0  896000.0  2062000.0   45.717769                 6.511748   \n",
       "...       ...   ...       ...        ...         ...                      ...   \n",
       "9997     9998   1.0  610000.0  2484000.0   19.506248                 8.030330   \n",
       "9998     9999   6.0  616000.0  2526000.0   24.992380                 0.158934   \n",
       "9999    10000   0.0  602000.0  2586000.0   26.211521                 0.004975   \n",
       "10000   10001   0.0  668000.0  2620000.0   12.496190                 0.028986   \n",
       "10001    6528   NaN       NaN        NaN         NaN                      NaN   \n",
       "\n",
       "       AvgAnnualN_Fert_1992_2001       AWC     AWS25   BFI  ...   Transmiss  \\\n",
       "0                      48.483771  0.141277  5.384314  21.0  ...  143.362904   \n",
       "1                      50.638261  0.217775  7.311919  37.0  ...  137.152244   \n",
       "2                      43.503552  0.140200  5.400000  33.0  ...  121.646066   \n",
       "3                      34.132068  0.154753  5.318469  37.0  ...  298.232568   \n",
       "4                      45.355325  0.140200  5.400000  28.0  ...   97.123320   \n",
       "...                          ...       ...       ...   ...  ...         ...   \n",
       "9997                   10.843744  0.159466  4.090000  59.0  ...  115.224598   \n",
       "9998                    0.199489  0.126106  4.030000  63.0  ...   40.882361   \n",
       "9999                    0.015434  0.126106  4.030000  66.0  ...   59.112810   \n",
       "10000                   0.058744  0.066700  2.000000  62.0  ...   59.639661   \n",
       "10001                        NaN       NaN       NaN   NaN  ...         NaN   \n",
       "\n",
       "             TWI        VRT       VWC  YngWtrMeanAge  YngWtrMeanAge_VertMean  \\\n",
       "0       9.902970   5.956547  0.304000      23.158235               17.689265   \n",
       "1       9.067347   4.196766  0.343552      22.015855               17.739371   \n",
       "2      11.470297  17.558480  0.270166      17.762669               15.950136   \n",
       "3       9.815662   1.231952  0.328985      27.709500               17.589893   \n",
       "4       9.435353  21.539828  0.268193      19.238581               14.557619   \n",
       "...          ...        ...       ...            ...                     ...   \n",
       "9997   13.790910   0.416030  0.344196       8.765928               16.686542   \n",
       "9998   11.154347   1.048951  0.253424      15.627269               11.281490   \n",
       "9999   13.113131   0.520421  0.280687      21.815356               15.832110   \n",
       "10000  12.550000   0.098656  0.367925       5.079691               14.141643   \n",
       "10001        NaN        NaN       NaN            NaN                     NaN   \n",
       "\n",
       "            DTW   Data  as10  Pred  \n",
       "0      3.082386  train   0.0  0.00  \n",
       "1      3.076582  train   0.0  0.06  \n",
       "2      5.645093  train   1.0  0.83  \n",
       "3      1.044807  train   0.0  0.03  \n",
       "4      8.535328  train   0.0  0.01  \n",
       "...         ...    ...   ...   ...  \n",
       "9997   0.188501   test   0.0  0.11  \n",
       "9998   1.518130   test   0.0  0.01  \n",
       "9999   0.643534   test   0.0  0.05  \n",
       "10000  0.114506   test   0.0  0.01  \n",
       "10001       NaN    NaN   NaN   NaN  \n",
       "\n",
       "[10002 rows x 87 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_arsenic_prelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kaPXyOxr3FWd"
   },
   "outputs": [],
   "source": [
    "df_arsenic_prelim.isnull().values.any()\n",
    "df_arsenic_prelim.isnull().sum()\n",
    "df_arsenic_prelim = df_arsenic_prelim.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7616, 87)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_arsenic_prelim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VmYE1jlO3FWg"
   },
   "outputs": [],
   "source": [
    "X = df_arsenic_prelim.iloc[:,4:-3]\n",
    "Y_TRUE = df_arsenic_prelim.iloc[:,1]\n",
    "Y_PRED_BIN = df_arsenic_prelim.iloc[:,-2]\n",
    "Y_PRED_CONTINUOUS = df_arsenic_prelim.iloc[:,-1]\n",
    "X_spatial_coods = df_arsenic_prelim.iloc[:,2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GI7HWbaA3FWh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7616, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_spatial_coods.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gC234b9p3FWh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range: 280.0\n",
      "Max: 280.0\n",
      "Max: 0.0\n"
     ]
    }
   ],
   "source": [
    "Y_TRUE\n",
    "r = np.ptp(Y_TRUE)\n",
    "print(\"Range:\", r)\n",
    "print(\"Max:\",max(Y_TRUE))\n",
    "print(\"Max:\",min(Y_TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7aTQa_En3FWh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  (7616, 80)\n",
      "Shape of Y_TRUE:  (7616,)\n",
      "Shape of Y_PRED_BIN:  (7616,)\n",
      "Shape of Y_PRED_CONFIDENCE:  (7616,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X: ', X.shape)\n",
    "print('Shape of Y_TRUE: ', Y_TRUE.shape)\n",
    "print('Shape of Y_PRED_BIN: ', Y_PRED_BIN.shape)\n",
    "print('Shape of Y_PRED_CONFIDENCE: ', Y_PRED_CONTINUOUS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hHlY_BE_3FWh"
   },
   "outputs": [],
   "source": [
    "No_of_train_samples = int((X.shape[0] * 3) / 4)\n",
    "remaining_samples = X.shape[0] - No_of_train_samples\n",
    "TrainX = np.array(X.iloc[:No_of_train_samples,:])\n",
    "TrainY = np.array(Y_TRUE)[:No_of_train_samples]\n",
    "\n",
    "No_of_valid_samples = int((TrainX.shape[0] * 3) / 4)\n",
    "ValidX = TrainX[No_of_valid_samples:,:]\n",
    "ValidY = TrainY[No_of_valid_samples:]\n",
    "\n",
    "TrainX = TrainX[:No_of_valid_samples,:]\n",
    "TrainY = TrainY[:No_of_valid_samples]\n",
    "\n",
    "TestX = np.array(X.iloc[No_of_train_samples:,:])\n",
    "TestY = np.array(Y_TRUE)[No_of_train_samples:]\n",
    "Test_old_pred = np.array(Y_PRED_CONTINUOUS)[No_of_train_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4284,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4284, 80)\n",
      "(4284,)\n",
      "(1428, 80)\n",
      "(1428,)\n",
      "(1904, 80)\n",
      "(1904,)\n",
      "(1904,)\n"
     ]
    }
   ],
   "source": [
    "print(TrainX.shape)\n",
    "print(TrainY.shape)\n",
    "print(ValidX.shape)\n",
    "print(ValidY.shape)\n",
    "print(TestX.shape)\n",
    "print(TestY.shape)\n",
    "print(Test_old_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "5niYM1LM3FWh"
   },
   "outputs": [],
   "source": [
    "Train_spatial =  np.array(X_spatial_coods.iloc[:No_of_train_samples,:])\n",
    "\n",
    "Valid_spatial = Train_spatial[No_of_valid_samples:,:]\n",
    "Train_spatial =  Train_spatial[:No_of_valid_samples,:]\n",
    "\n",
    "Test_spatial =  np.array(X_spatial_coods.iloc[No_of_train_samples:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4284, 2)\n",
      "(1428, 2)\n",
      "(1904, 2)\n"
     ]
    }
   ],
   "source": [
    "print(Train_spatial.shape)\n",
    "print(Valid_spatial.shape)\n",
    "print(Test_spatial.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PTcP7oNL3FWi"
   },
   "outputs": [],
   "source": [
    "#scaler_1 = sklearn.preprocessing.StandardScaler()\n",
    "scaler_1 = sklearn.preprocessing.MinMaxScaler()\n",
    "scaler_1 = scaler_1.fit(TrainX)\n",
    "\n",
    "TrainX = scaler_1.transform(TrainX)\n",
    "TestX = scaler_1.transform(TestX)\n",
    "ValidX = scaler_1.transform(ValidX)\n",
    "\n",
    "#scaler_2 = sklearn.preprocessing.StandardScaler()\n",
    "scaler_2 = sklearn.preprocessing.MinMaxScaler()\n",
    "scaler_2 = scaler_2.fit(TrainY.reshape(-1,1))\n",
    "\n",
    "TrainY = scaler_2.transform(TrainY.reshape(-1,1))\n",
    "TestY = scaler_2.transform(TestY.reshape(-1,1))\n",
    "ValidY = scaler_2.transform(ValidY.reshape(-1,1))\n",
    "\n",
    "\n",
    "TrainY = TrainY.reshape(-1)\n",
    "TestY = TestY.reshape(-1)\n",
    "ValidY = ValidY.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4284,)\n"
     ]
    }
   ],
   "source": [
    "print(TrainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4284, 80)\n",
      "(4284,)\n",
      "(1428, 80)\n",
      "(1428,)\n",
      "(1904, 80)\n",
      "(1904,)\n",
      "(1904,)\n"
     ]
    }
   ],
   "source": [
    "print(TrainX.shape)\n",
    "print(TrainY.shape)\n",
    "print(ValidX.shape)\n",
    "print(ValidY.shape)\n",
    "print(TestX.shape)\n",
    "print(TestY.shape)\n",
    "print(Test_old_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "sfgDvvus3FWi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TrainX:  (4284, 80)\n",
      "Shape of TestX:  (1904, 80)\n",
      "Shape of TrainY:  (4284,)\n",
      "Shape of TestY:  (1904,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of TrainX: ', TrainX.shape)\n",
    "print('Shape of TestX: ', TestX.shape)\n",
    "print('Shape of TrainY: ', TrainY.shape)\n",
    "print('Shape of TestY: ', TestY.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4QH7j8x3FWi"
   },
   "source": [
    "Edge matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "imM0CEpm3FWj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train_spatial: (4284, 2)\n",
      "Shape of Test_spatial: (1904, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Train_spatial:',Train_spatial.shape)\n",
    "print('Shape of Test_spatial:',Test_spatial.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "xVIiZ-Tq3FWj"
   },
   "outputs": [],
   "source": [
    "no_of_train_samples = TrainX.shape[0]\n",
    "no_of_test_samples = TestX.shape[0]\n",
    "no_of_valid_samples = ValidX.shape[0]\n",
    "\n",
    "Train_euclidean = np.empty((no_of_train_samples,no_of_train_samples))\n",
    "Valid_euclidean = np.empty((no_of_valid_samples,no_of_valid_samples))\n",
    "Test_euclidean = np.empty((no_of_test_samples,no_of_test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4284, 4284)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_euclidean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "VO5C3wlr3FWj"
   },
   "outputs": [],
   "source": [
    "for i in range(no_of_train_samples):\n",
    "    for j in range(no_of_train_samples):\n",
    "        a = Train_spatial[i,0],Train_spatial[i,1]\n",
    "        b = Train_spatial[j,0],Train_spatial[j,1]\n",
    "        dist = [(a - b)**2 for a, b in zip(a, b)]\n",
    "        Train_euclidean[i,j] = math.sqrt(sum(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(no_of_valid_samples):\n",
    "    for j in range(no_of_valid_samples):\n",
    "        a = Valid_spatial[i,0],Valid_spatial[i,1]\n",
    "        b = Valid_spatial[j,0],Valid_spatial[j,1]\n",
    "        dist = [(a - b)**2 for a, b in zip(a, b)]\n",
    "        Valid_euclidean[i,j] = math.sqrt(sum(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1428, 1428)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Valid_euclidean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "7Z3wFUjf3FWk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4284, 4284)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_euclidean.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "C2bBuC0q3FWk"
   },
   "outputs": [],
   "source": [
    "for i in range(no_of_test_samples):\n",
    "    for j in range(no_of_test_samples):\n",
    "        a = Test_spatial[i,0],Test_spatial[i,1]\n",
    "        b = Test_spatial[j,0],Test_spatial[j,1]\n",
    "        dist = [(a - b)**2 for a, b in zip(a, b)]\n",
    "        Test_euclidean[i,j] = math.sqrt(sum(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1904, 1904)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_euclidean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_edges = np.empty((no_of_train_samples,no_of_train_samples))\n",
    "Valid_edges = np.empty((no_of_valid_samples,no_of_valid_samples))\n",
    "Test_edges = np.empty((no_of_test_samples,no_of_test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_off_val = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(no_of_train_samples):\n",
    "    for j in range(no_of_train_samples):\n",
    "        if (Train_euclidean[i,j] < cut_off_val) and i!=j:\n",
    "            Train_edges[i,j]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4284, 4284)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(no_of_valid_samples):\n",
    "    for j in range(no_of_valid_samples):\n",
    "        if (Valid_euclidean[i,j] < cut_off_val) and i!=j :\n",
    "            Valid_edges[i,j]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1428, 1428)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Valid_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(no_of_test_samples):\n",
    "    for j in range(no_of_test_samples):\n",
    "        if (Test_euclidean[i,j] < cut_off_val) and i!=j:\n",
    "            Test_edges[i,j]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1904, 1904)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "8yCw1Enl3FWm"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 127] The specified procedure could not be found. Error loading \"C:\\anaconda\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-752bb4d65e24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcontext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mupdate_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWinError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrerror\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34mf' Error loading \"{dll}\" or one of its dependencies.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[0mis_loaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 127] The specified procedure could not be found. Error loading \"C:\\anaconda\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from context import update_path\n",
    "\n",
    "update_path(os.path.join(\"..\", \"HydroLearn_Dev\"))\n",
    "\n",
    "import Utility as util\n",
    "from Container import Container\n",
    "from Models.Model import Model, GNN, SummaryWriter, StandardLoader, batch_sampler_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0A__c3s3FWm"
   },
   "outputs": [],
   "source": [
    "class Variables(Container):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.training = self.training_var(Container())\n",
    "        self.checkpointing = self.checkpointing_var(Container())\n",
    "\n",
    "    def training_var(self, con):\n",
    "        con.set(\"train\", True)\n",
    "        con.set(\"n_epochs\", 100)\n",
    "        con.set(\"early_stop_epochs\", -1)\n",
    "        con.set(\"mbatch_size\", 512)\n",
    "        con.set(\"lr\", 0.001)\n",
    "        con.set(\"lr_decay\", 0.0)\n",
    "        con.set(\"param_lr_map\", {})\n",
    "        con.set(\"gradient_clip\", None)\n",
    "        con.set(\"regularization\", 0.0)\n",
    "        con.set(\"l1_reg\", 0.0)\n",
    "        con.set(\"l2_reg\", 0.0)\n",
    "        con.set(\"optimizer\", \"SGD\")\n",
    "        con.set(\"loss\", \"MSELoss\")\n",
    "        con.set(\"initializer\", None)\n",
    "        con.set(\"initialization_seed\", 0)\n",
    "        con.set(\"batch_shuffle_seed\", 0)\n",
    "        con.set(\"use_gpu\", True)\n",
    "        con.set(\"gpu_data_mapping\", \"all\")\n",
    "        con.set(\"partition_indices\", None, \"train\")\n",
    "        con.set(\"partition_indices\", None, \"valid\")\n",
    "        con.set(\"partition_indices\", None, \"test\")\n",
    "        return con\n",
    "\n",
    "    def checkpointing_var(self, con):\n",
    "        con.set(\"checkpoint_dir\", \"Checkpoints\")\n",
    "        con.set(\"checkpoint_epochs\", -1)\n",
    "        return con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lecun_normal_(tensor: torch.Tensor) -> torch.Tensor:\n",
    "    input_size = tensor.shape[-1] # Assuming that the weights' input dimension is the last.\n",
    "    std = math.sqrt(1/input_size)\n",
    "    with torch.no_grad():\n",
    "        return tensor.normal_(-std,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDLyWu293FWn"
   },
   "outputs": [],
   "source": [
    "class _StandardLoader(StandardLoader):\n",
    "    \n",
    "    def sampled_items(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore this part - Modify this\n",
    "\n",
    "class MLPGNN(Model):\n",
    "\n",
    "    def __init__(self, in_size, out_size, hidden_size, dropout=0.0):\n",
    "        super(MLPGNN, self).__init__()\n",
    "        # layers\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_size, 200),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(200, 100),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(100, 50),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(50, 32),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "        )\n",
    "        self.gnn = GNN(32, 32, 32, n_hops=1, dropout=dropout)\n",
    "        self.out_proj = torch.nn.Linear(32, out_size)\n",
    "        self.out_proj_act = torch.nn.SELU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "#        self.debug = 1\n",
    "        self.gnn.debug = self.debug\n",
    "        x = inputs[\"X\"]\n",
    "        edge_indices = inputs[\"edge_indices\"]\n",
    "        if self.debug:\n",
    "            print(\"x =\", x.shape)\n",
    "            print(\"edge_indices =\", edge_indices.shape)\n",
    "        a = self.mlp(x)\n",
    "        if self.debug:\n",
    "            print(\"mlp out =\", a.shape)\n",
    "        b = self.gnn(X=a, edge_indices=edge_indices)[\"Yhat\"]\n",
    "        if self.debug:\n",
    "            print(\"gnn out =\", b.shape)\n",
    "        output = self.out_proj(b)\n",
    "        if self.debug:\n",
    "            print(\"out_proj out =\", output.shape)\n",
    "        fin_res = self.out_proj_act(output)\n",
    "        if self.debug:\n",
    "            sys.exit(1)\n",
    "        return {\"Yhat\": fin_res}\n",
    "\n",
    "    def optimize(self, train, valid, test, var):\n",
    "        self.use_gpu = var.use_gpu\n",
    "        self.all_to_gpu = var.use_gpu and var.gpu_data_mapping == \"all\"\n",
    "        self.mbatches_to_gpu = var.use_gpu and var.gpu_data_mapping == \"minibatch\"\n",
    "        self, train = self.prepare(train, var.use_gpu)\n",
    "        # Initialize loaders, loss, optimizer, parameters, etc\n",
    "        train_iterable = self.LoaderDatasetClass()(train, var)\n",
    "        sampler = torch.utils.data.BatchSampler(\n",
    "            torch.utils.data.RandomSampler(\n",
    "                train_iterable,\n",
    "                generator=torch.Generator().manual_seed(\n",
    "                    var.batch_shuffle_seed if var.batch_shuffle_seed > -1 else time.time()\n",
    "                )\n",
    "            ),\n",
    "            var.mbatch_size,\n",
    "            True\n",
    "        )\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_iterable,\n",
    "            sampler=sampler,\n",
    "            collate_fn=batch_sampler_collate,\n",
    "        )\n",
    "        if not valid is None:\n",
    "            self, valid = self.prepare(valid, var.use_gpu)\n",
    "            valid_iterable = self.LoaderDatasetClass()(valid, var)\n",
    "            sampler = torch.utils.data.BatchSampler(\n",
    "                torch.utils.data.SequentialSampler(valid_iterable),\n",
    "                var.mbatch_size,\n",
    "                False\n",
    "            )\n",
    "            valid_loader = torch.utils.data.DataLoader(\n",
    "                valid_iterable,\n",
    "                sampler=sampler,\n",
    "                collate_fn=batch_sampler_collate,\n",
    "            )\n",
    "        if not test is None:\n",
    "            self, test = self.prepare(test, var.use_gpu)\n",
    "            test_iterable = self.LoaderDatasetClass()(test, var)\n",
    "            sampler = torch.utils.data.BatchSampler(\n",
    "                torch.utils.data.SequentialSampler(test_iterable),\n",
    "                var.mbatch_size,\n",
    "                False\n",
    "            )\n",
    "            test_loader = torch.utils.data.DataLoader(\n",
    "                test_iterable,\n",
    "                sampler=sampler,\n",
    "                collate_fn=batch_sampler_collate,\n",
    "            )\n",
    "        self.crit = self.criterion(var)\n",
    "        self.opt = self.optimizer(var)\n",
    "        self.init_params(var.initializer, var.initialization_seed)\n",
    "        self.summary_writer = SummaryWriter(var.checkpoint_dir)\n",
    "        self.summary_writer.add_text(\"Model\", str(self).replace(\"\\n\", \"\\n\\n\"))\n",
    "        # Commence optimization\n",
    "        self.train_losses, self.valid_losses, self.test_losses = [], [], []\n",
    "        n_plateau_epochs, min_valid_loss = 0, sys.float_info.max\n",
    "        for epoch in range(var.n_epochs+1):\n",
    "            print(35 * \"+\")\n",
    "            self.train()\n",
    "            var.current_partition = \"train\"\n",
    "            epoch_loss, n_sample = 0, 0\n",
    "            self.pre_epoch_update(train, train_loader, valid, valid_loader, test, test_loader, epoch, var)\n",
    "            for mb_in in train_loader: # Training set pass\n",
    "                mb_in = util.merge_dicts(mb_in, train, False)\n",
    "                if self.mbatches_to_gpu:\n",
    "                    start = time.time()\n",
    "                    for key in mb_in.keys():\n",
    "                        mb_in[key] = util.to_device(mb_in[key], util.get_device(True))\n",
    "                    self.to_gpu_time += time.time() - start\n",
    "                mb_out = self.forward(mb_in)\n",
    "                if self.mbatches_to_gpu:\n",
    "                    start = time.time()\n",
    "                    for key in mb_in.keys():\n",
    "                        mb_in[key] = util.to_device(mb_in[key], util.get_device(False))\n",
    "                    self.to_cpu_time += time.time() - start\n",
    "                mb_loss = self.loss(mb_in, mb_out, var)\n",
    "                if epoch > 0:\n",
    "                    self.step(mb_loss, mb_in, mb_out, var)\n",
    "                epoch_loss += self.loss_to_numeric(mb_loss, var)\n",
    "            epoch_loss /= len(train_loader)\n",
    "            self.train_losses += [epoch_loss]\n",
    "            print(\"Epoch %d : Train Loss = %.5f\" % (epoch, epoch_loss))\n",
    "            self.eval()\n",
    "            self.post_epoch_update(train, train_loader, valid, valid_loader, test, test_loader, epoch, var)\n",
    "            if not valid is None: # Validation set pass\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    var.current_partition = \"valid\"\n",
    "                    epoch_loss, n_sample = 0, 0\n",
    "                    for mb_in in valid_loader:\n",
    "                        mb_in = util.merge_dicts(mb_in, valid, False)\n",
    "                        if self.mbatches_to_gpu:\n",
    "                            start = time.time()\n",
    "                            for key in mb_in.keys():\n",
    "                                mb_in[key] = util.to_device(mb_in[key], util.get_device(True))\n",
    "                            self.to_gpu_time += time.time() - start\n",
    "                        mb_out = self.forward(mb_in)\n",
    "                        if self.mbatches_to_gpu:\n",
    "                            start = time.time()\n",
    "                            for key in mb_in.keys():\n",
    "                                mb_in[key] = util.to_device(mb_in[key], util.get_device(False))\n",
    "                            self.to_cpu_time += time.time() - start\n",
    "                        mb_loss = self.loss(mb_in, mb_out,var)\n",
    "                        epoch_loss += self.loss_to_numeric(mb_loss, var)\n",
    "                    epoch_loss /= len(valid_loader)\n",
    "                    print(\"Epoch %d : Valid Loss = %.5f\" % (epoch, epoch_loss))\n",
    "                    self.valid_losses += [epoch_loss]\n",
    "                    if epoch_loss < min_valid_loss: # Check for improvement and update early stopping\n",
    "                        min_valid_loss = epoch_loss\n",
    "                        n_plateau_epochs = 0\n",
    "                        path = os.sep.join([var.checkpoint_dir, \"Best.pth\"])\n",
    "                        self.checkpoint(path)\n",
    "                    else:\n",
    "                        n_plateau_epochs += 1\n",
    "                        if var.early_stop_epochs > 0 and n_plateau_epochs % var.early_stop_epochs == 0:\n",
    "                            break\n",
    "            if not test is None: # Testing set pass\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    var.current_partition = \"test\"\n",
    "                    epoch_loss, n_sample = 0, 0\n",
    "                    for mb_in in test_loader:\n",
    "                        mb_in = util.merge_dicts(mb_in, test, False)\n",
    "                        if self.mbatches_to_gpu:\n",
    "                            start = time.time()\n",
    "                            for key in mb_in.keys():\n",
    "                                mb_in[key] = util.to_device(mb_in[key], util.get_device(True))\n",
    "                            self.to_cpu_time += time.time() - start\n",
    "                        mb_out = self.forward(mb_in)\n",
    "                        if self.mbatches_to_gpu:\n",
    "                            start = time.time()\n",
    "                            for key in mb_in.keys():\n",
    "                                mb_in[key] = util.to_device(mb_in[key], util.get_device(False))\n",
    "                            self.to_cpu_time += time.time() - start\n",
    "                        mb_loss = self.loss(mb_in, mb_out, var)\n",
    "                        epoch_loss += self.loss_to_numeric(mb_loss, var)\n",
    "                    epoch_loss /= len(test_loader)\n",
    "                    print(\"Epoch %d :  Test Loss = %.5f\" % (epoch, epoch_loss))\n",
    "                    self.test_losses += [epoch_loss]\n",
    "            print(35 * \"+\")\n",
    "            self.update_optimizer(epoch, var)\n",
    "            self.log_epoch_info(train, train_loader, valid, valid_loader, test, test_loader, epoch, var)\n",
    "        self.summary_writer.close()\n",
    "        # Save final model\n",
    "        path = os.sep.join([var.checkpoint_dir, \"Final.pth\"])\n",
    "        self.checkpoint(path)\n",
    "        # Return data to original device (cpu), shape, and type (NumPy.ndarray)\n",
    "        self, train = self.prepare(train, False, True)\n",
    "        if not valid_X is None and valid_Y is None:\n",
    "            self, valid = self.prepare(valid, False, True)\n",
    "        if not test_X is None and test_Y is None:\n",
    "            self, test = self.prepare(test, False, True)\n",
    "\n",
    "    def LoaderDatasetClass(self):\n",
    "        return _StandardLoader\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for name, layer in self.mlp._modules.items():\n",
    "            if hasattr(layer, \"reset_parameters\"):\n",
    "                layer.reset_parameters()\n",
    "        self.gnn.reset_parameters()\n",
    "        self.out_proj.reset_parameters()\n",
    "        \n",
    "    def criterion(self, var):\n",
    "        return self.loss_fn_map[var.loss](reduction=\"none\")\n",
    "    \n",
    "    def loss(self, mb_in, mb_out, var):\n",
    "        debug = 0\n",
    "        Yhat = mb_out[\"Yhat\"]\n",
    "        Y = mb_in[\"Y\"]\n",
    "        if debug:\n",
    "            print(\"Yhat =\", Yhat.shape)\n",
    "            print(\"Y =\", Y.shape)\n",
    "        mb_indices = mb_in[\"__index__\"]\n",
    "        if debug:\n",
    "            print(\"mb_indices =\", \"len(%d)\" % len(mb_indices), \"=\", mb_indices)\n",
    "        Yhat = Yhat[mb_indices]\n",
    "        Y = Y[mb_indices]\n",
    "        if debug:\n",
    "            print(\"Yhat =\", Yhat.shape)\n",
    "            print(\"Y =\", Y.shape)\n",
    "        errors = self.crit(Yhat, Y)\n",
    "        if debug:\n",
    "            print(\"errors =\", errors.shape)\n",
    "        loss_weights = var.get(\"loss_weights\", var.current_partition)[mb_indices]\n",
    "        if debug:\n",
    "            print(\"loss_weights =\", loss_weights.shape)\n",
    "        error = torch.mean(loss_weights[:,None] * errors)\n",
    "        if debug:\n",
    "            print(\"error =\", error.shape)\n",
    "        if debug:\n",
    "            input()\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eW7-HcEK0fww"
   },
   "outputs": [],
   "source": [
    "# ignore this part - Preserve this\n",
    "\n",
    "class MLPGNN(Model):\n",
    "\n",
    "    def __init__(self, in_size, out_size, hidden_size, dropout=0.0):\n",
    "        super(MLPGNN, self).__init__()\n",
    "        # layers\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_size, 200),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(200, 80),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(80, 75),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(75, 54),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(54, 32),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "        )\n",
    "        self.gnn = GNN(32, 32, 32, n_hops=1, dropout=dropout)\n",
    "        self.out_proj = torch.nn.Linear(32, out_size)\n",
    "        self.out_proj_act = torch.nn.Identity()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "#        self.debug = 1\n",
    "        self.gnn.debug = self.debug\n",
    "        x = inputs[\"X\"]\n",
    "        edge_indices = inputs[\"edge_indices\"]\n",
    "        if self.debug:\n",
    "            print(\"x =\", x.shape)\n",
    "            print(\"edge_indices =\", edge_indices.shape)\n",
    "        a = self.mlp(x)\n",
    "        if self.debug:\n",
    "            print(\"mlp out =\", a.shape)\n",
    "        b = self.gnn(X=a, edge_indices=edge_indices)[\"Yhat\"]\n",
    "        if self.debug:\n",
    "            print(\"gnn out =\", b.shape)\n",
    "        output = self.out_proj(b)\n",
    "        if self.debug:\n",
    "            print(\"out_proj out =\", output.shape)\n",
    "        fin_res = self.out_proj_act(output)\n",
    "        if self.debug:\n",
    "            sys.exit(1)\n",
    "        return {\"Yhat\": fin_res}\n",
    "\n",
    "    def optimize(self, train, valid, test, var):\n",
    "        self.use_gpu = var.use_gpu\n",
    "        self.all_to_gpu = var.use_gpu and var.gpu_data_mapping == \"all\"\n",
    "        self.mbatches_to_gpu = var.use_gpu and var.gpu_data_mapping == \"minibatch\"\n",
    "        self, train = self.prepare(train, var.use_gpu)\n",
    "        # Initialize loaders, loss, optimizer, parameters, etc\n",
    "        train_iterable = self.LoaderDatasetClass()(train, var)\n",
    "        sampler = torch.utils.data.BatchSampler(\n",
    "            torch.utils.data.RandomSampler(\n",
    "                train_iterable,\n",
    "                generator=torch.Generator().manual_seed(\n",
    "                    var.batch_shuffle_seed if var.batch_shuffle_seed > -1 else time.time()\n",
    "                )\n",
    "            ),\n",
    "            var.mbatch_size,\n",
    "            True\n",
    "        )\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_iterable,\n",
    "            sampler=sampler,\n",
    "            collate_fn=batch_sampler_collate,\n",
    "        )\n",
    "        if not valid is None:\n",
    "            self, valid = self.prepare(valid, var.use_gpu)\n",
    "            valid_iterable = self.LoaderDatasetClass()(valid, var)\n",
    "            sampler = torch.utils.data.BatchSampler(\n",
    "                torch.utils.data.SequentialSampler(valid_iterable),\n",
    "                var.mbatch_size,\n",
    "                False\n",
    "            )\n",
    "            valid_loader = torch.utils.data.DataLoader(\n",
    "                valid_iterable,\n",
    "                sampler=sampler,\n",
    "                collate_fn=batch_sampler_collate,\n",
    "            )\n",
    "        if not test is None:\n",
    "            self, test = self.prepare(test, var.use_gpu)\n",
    "            test_iterable = self.LoaderDatasetClass()(test, var)\n",
    "            sampler = torch.utils.data.BatchSampler(\n",
    "                torch.utils.data.SequentialSampler(test_iterable),\n",
    "                var.mbatch_size,\n",
    "                False\n",
    "            )\n",
    "            test_loader = torch.utils.data.DataLoader(\n",
    "                test_iterable,\n",
    "                sampler=sampler,\n",
    "                collate_fn=batch_sampler_collate,\n",
    "            )\n",
    "        self.crit = self.criterion(var)\n",
    "        self.opt = self.optimizer(var)\n",
    "        self.init_params(var.initializer, var.initialization_seed)\n",
    "        self.summary_writer = SummaryWriter(var.checkpoint_dir)\n",
    "        self.summary_writer.add_text(\"Model\", str(self).replace(\"\\n\", \"\\n\\n\"))\n",
    "        # Commence optimization\n",
    "        self.train_losses, self.valid_losses, self.test_losses = [], [], []\n",
    "        n_plateau_epochs, min_valid_loss = 0, sys.float_info.max\n",
    "        for epoch in range(var.n_epochs+1):\n",
    "            print(35 * \"+\")\n",
    "            self.train()\n",
    "            var.current_partition = \"train\"\n",
    "            epoch_loss, n_sample = 0, 0\n",
    "            self.pre_epoch_update(train, train_loader, valid, valid_loader, test, test_loader, epoch, var)\n",
    "            for mb_in in train_loader: # Training set pass\n",
    "                mb_in = util.merge_dicts(mb_in, train, False)\n",
    "                if self.mbatches_to_gpu:\n",
    "                    start = time.time()\n",
    "                    for key in mb_in.keys():\n",
    "                        mb_in[key] = util.to_device(mb_in[key], util.get_device(True))\n",
    "                    self.to_gpu_time += time.time() - start\n",
    "                mb_out = self.forward(mb_in)\n",
    "                if self.mbatches_to_gpu:\n",
    "                    start = time.time()\n",
    "                    for key in mb_in.keys():\n",
    "                        mb_in[key] = util.to_device(mb_in[key], util.get_device(False))\n",
    "                    self.to_cpu_time += time.time() - start\n",
    "                mb_loss = self.loss(mb_in, mb_out, var)\n",
    "                if epoch > 0:\n",
    "                    self.step(mb_loss, mb_in, mb_out, var)\n",
    "                epoch_loss += self.loss_to_numeric(mb_loss, var)\n",
    "            epoch_loss /= len(train_loader)\n",
    "            self.train_losses += [epoch_loss]\n",
    "            print(\"Epoch %d : Train Loss = %.5f\" % (epoch, epoch_loss))\n",
    "            self.eval()\n",
    "            self.post_epoch_update(train, train_loader, valid, valid_loader, test, test_loader, epoch, var)\n",
    "            if not valid is None: # Validation set pass\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    var.current_partition = \"valid\"\n",
    "                    epoch_loss, n_sample = 0, 0\n",
    "                    for mb_in in valid_loader:\n",
    "                        mb_in = util.merge_dicts(mb_in, valid, False)\n",
    "                        if self.mbatches_to_gpu:\n",
    "                            start = time.time()\n",
    "                            for key in mb_in.keys():\n",
    "                                mb_in[key] = util.to_device(mb_in[key], util.get_device(True))\n",
    "                            self.to_gpu_time += time.time() - start\n",
    "                        mb_out = self.forward(mb_in)\n",
    "                        if self.mbatches_to_gpu:\n",
    "                            start = time.time()\n",
    "                            for key in mb_in.keys():\n",
    "                                mb_in[key] = util.to_device(mb_in[key], util.get_device(False))\n",
    "                            self.to_cpu_time += time.time() - start\n",
    "                        mb_loss = self.loss(mb_in, mb_out,var)\n",
    "                        epoch_loss += self.loss_to_numeric(mb_loss, var)\n",
    "                    epoch_loss /= len(valid_loader)\n",
    "                    print(\"Epoch %d : Valid Loss = %.5f\" % (epoch, epoch_loss))\n",
    "                    self.valid_losses += [epoch_loss]\n",
    "                    if epoch_loss < min_valid_loss: # Check for improvement and update early stopping\n",
    "                        min_valid_loss = epoch_loss\n",
    "                        n_plateau_epochs = 0\n",
    "                        path = os.sep.join([var.checkpoint_dir, \"Best.pth\"])\n",
    "                        self.checkpoint(path)\n",
    "                    else:\n",
    "                        n_plateau_epochs += 1\n",
    "                        if var.early_stop_epochs > 0 and n_plateau_epochs % var.early_stop_epochs == 0:\n",
    "                            break\n",
    "            if not test is None: # Testing set pass\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    var.current_partition = \"test\"\n",
    "                    epoch_loss, n_sample = 0, 0\n",
    "                    for mb_in in test_loader:\n",
    "                        mb_in = util.merge_dicts(mb_in, test, False)\n",
    "                        if self.mbatches_to_gpu:\n",
    "                            start = time.time()\n",
    "                            for key in mb_in.keys():\n",
    "                                mb_in[key] = util.to_device(mb_in[key], util.get_device(True))\n",
    "                            self.to_cpu_time += time.time() - start\n",
    "                        mb_out = self.forward(mb_in)\n",
    "                        if self.mbatches_to_gpu:\n",
    "                            start = time.time()\n",
    "                            for key in mb_in.keys():\n",
    "                                mb_in[key] = util.to_device(mb_in[key], util.get_device(False))\n",
    "                            self.to_cpu_time += time.time() - start\n",
    "                        mb_loss = self.loss(mb_in, mb_out, var)\n",
    "                        epoch_loss += self.loss_to_numeric(mb_loss, var)\n",
    "                    epoch_loss /= len(test_loader)\n",
    "                    print(\"Epoch %d :  Test Loss = %.5f\" % (epoch, epoch_loss))\n",
    "                    self.test_losses += [epoch_loss]\n",
    "            print(35 * \"+\")\n",
    "            self.update_optimizer(epoch, var)\n",
    "            self.log_epoch_info(train, train_loader, valid, valid_loader, test, test_loader, epoch, var)\n",
    "        self.summary_writer.close()\n",
    "        # Save final model\n",
    "        path = os.sep.join([var.checkpoint_dir, \"Final.pth\"])\n",
    "        self.checkpoint(path)\n",
    "        # Return data to original device (cpu), shape, and type (NumPy.ndarray)\n",
    "        self, train = self.prepare(train, False, True)\n",
    "        if not valid_X is None and valid_Y is None:\n",
    "            self, valid = self.prepare(valid, False, True)\n",
    "        if not test_X is None and test_Y is None:\n",
    "            self, test = self.prepare(test, False, True)\n",
    "\n",
    "    def LoaderDatasetClass(self):\n",
    "        return _StandardLoader\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for name, layer in self.mlp._modules.items():\n",
    "            if hasattr(layer, \"reset_parameters\"):\n",
    "                layer.reset_parameters()\n",
    "        self.gnn.reset_parameters()\n",
    "        self.out_proj.reset_parameters()\n",
    "        \n",
    "    def criterion(self, var):\n",
    "        return self.loss_fn_map[var.loss](reduction=\"none\")\n",
    "    \n",
    "    def loss(self, mb_in, mb_out, var):\n",
    "        debug = 0\n",
    "        Yhat = mb_out[\"Yhat\"]\n",
    "        Y = mb_in[\"Y\"]\n",
    "        if debug:\n",
    "            print(\"Yhat =\", Yhat.shape)\n",
    "            print(\"Y =\", Y.shape)\n",
    "        mb_indices = mb_in[\"__index__\"]\n",
    "        if debug:\n",
    "            print(\"mb_indices =\", \"len(%d)\" % len(mb_indices), \"=\", mb_indices)\n",
    "        Yhat = Yhat[mb_indices]\n",
    "        Y = Y[mb_indices]\n",
    "        if debug:\n",
    "            print(\"Yhat =\", Yhat.shape)\n",
    "            print(\"Y =\", Y.shape)\n",
    "        errors = self.crit(Yhat, Y)\n",
    "        if debug:\n",
    "            print(\"errors =\", errors.shape)\n",
    "        loss_weights = var.get(\"loss_weights\", var.current_partition)[mb_indices]\n",
    "        if debug:\n",
    "            print(\"loss_weights =\", loss_weights.shape)\n",
    "        error = torch.mean(loss_weights[:,None] * errors)\n",
    "        if debug:\n",
    "            print(\"error =\", error.shape)\n",
    "        if debug:\n",
    "            input()\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_numpy_matrix(Train_edges)\n",
    "n = G.number_of_nodes()\n",
    "m = G.number_of_edges()\n",
    "print(n,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_edges_list = np.array([e for e in G.edges])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_edges_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Valid_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_numpy_matrix(Valid_edges)\n",
    "n = G.number_of_nodes()\n",
    "m = G.number_of_edges()\n",
    "print(n,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Valid_edges_list = np.array([e for e in G.edges])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Valid_edges_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_edges.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = nx.from_numpy_matrix(Test_edges)\n",
    "n = G1.number_of_nodes()\n",
    "m = G1.number_of_edges()\n",
    "print(n,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_edges_list = np.array([e for e in G1.edges])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_edges_list = Train_edges_list.reshape(2,Train_edges_list.shape[0])\n",
    "Test_edges_list = Test_edges_list.reshape(2,Test_edges_list.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Valid_edges_list = Valid_edges_list.reshape(2,Valid_edges_list.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Train_edges_list.shape)\n",
    "print(Test_edges_list.shape)\n",
    "print(Valid_edges_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_weights = pd.read_csv (r'C:\\Users\\Ryan\\Desktop\\Research\\n_data\\Datapoint_weights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainX.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3.599999999999999867e-01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7615.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.940972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.951550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>76.160000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       3.599999999999999867e-01\n",
       "count               7615.000000\n",
       "mean                   0.940972\n",
       "std                    4.951550\n",
       "min                    0.040000\n",
       "25%                    0.040000\n",
       "50%                    0.080000\n",
       "75%                    0.190000\n",
       "max                   76.160000"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_weights.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dont run this cell for now\n",
    "\n",
    "loss_weights_train = np.empty((TrainX.shape[0],1))\n",
    "loss_weights_valid =  np.empty((ValidX.shape[0],1))\n",
    "loss_weights_test = np.empty((TestX.shape[0],1))\n",
    "\n",
    "loss_weights_train.shape\n",
    "loss_weights_train[1:].shape\n",
    "loss_weights_train[0,0]\n",
    "\n",
    "loss_weights_train[1:] = loss_weights[:TrainX.shape[0]-1]\n",
    "loss_weight_valid = loss_weights[TrainX.shape[0]-1:(TrainX.shape[0]-1) + ValidX.shape[0] ]\n",
    "loss_weights_test = loss_weights[(TrainX.shape[0]-1) + ValidX.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_weights_train = np.ones(TrainX.shape[0])\n",
    "loss_weights_valid = np.ones(ValidX.shape[0])\n",
    "loss_weights_test =  np.ones(TestX.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4284,)\n",
      "(1904,)\n",
      "(1428,)\n"
     ]
    }
   ],
   "source": [
    "print(loss_weights_train.shape)\n",
    "print(loss_weights_test.shape)\n",
    "print(loss_weights_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-432e8ec0470b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:0\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-716a358b95c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss_weights_train_torch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_weights_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mloss_weights_valid_torch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_weights_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mloss_weights_test_torch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_weights_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "loss_weights_train_torch = torch.from_numpy(np.array(loss_weights_train)).float().to(device)\n",
    "loss_weights_valid_torch = torch.from_numpy(np.array(loss_weights_valid)).float().to(device)\n",
    "loss_weights_test_torch = torch.from_numpy(np.array(loss_weights_test)).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_weights_train_torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-65ec24ea4bf5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss_weights_train_torch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_weights_train_torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mloss_weights_valid_torch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_weights_valid_torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mloss_weights_test_torch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_weights_test_torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss_weights_train_torch' is not defined"
     ]
    }
   ],
   "source": [
    "loss_weights_train_torch = loss_weights_train_torch.reshape(-1)\n",
    "loss_weights_valid_torch = loss_weights_valid_torch.reshape(-1)\n",
    "loss_weights_test_torch = loss_weights_test_torch.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_weights_train_torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-10a932556bb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_weights_train_torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_weights_valid_torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_weights_test_torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss_weights_train_torch' is not defined"
     ]
    }
   ],
   "source": [
    "print(loss_weights_train_torch.shape)\n",
    "print(loss_weights_valid_torch.shape)\n",
    "print(loss_weights_test_torch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Train_edges_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-3733395f5104>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTrain_edges_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Train_edges_list' is not defined"
     ]
    }
   ],
   "source": [
    "Train_edges_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Valid_edges_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-4069d211f69d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mValid_edges_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Valid_edges_list' is not defined"
     ]
    }
   ],
   "source": [
    "Valid_edges_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Test_edges_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-54f0e4489d0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTest_edges_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Test_edges_list' is not defined"
     ]
    }
   ],
   "source": [
    "Test_edges_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4284, 80)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4284,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1428, 80)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ValidX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1428,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ValidY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-34dba1d21554>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test_X' is not defined"
     ]
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-7c6cbbf51f57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_Y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test_Y' is not defined"
     ]
    }
   ],
   "source": [
    "test_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Train_edges_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-59eb8fb087b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Construct graph for each partition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mtrain_edge_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrain_edges_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mvalid_edge_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mValid_edges_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mtest_edge_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTest_edges_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Train_edges_list' is not defined"
     ]
    }
   ],
   "source": [
    "# Setup - modified-2\n",
    "import numpy as np\n",
    "X = np.random.normal(size=(1000, 80))\n",
    "Y = np.ones((1000, 1))\n",
    "##### TODO #####\n",
    "#\n",
    "# Split X and Y into train, valid, and test sets\n",
    "#    partition such that valid and test are each 10% of all samples but taken from a condensed region (not sampled randomly)\n",
    "#\n",
    "train_X = TrainX\n",
    "train_Y = TrainY\n",
    "valid_X = ValidX\n",
    "valid_Y = ValidY\n",
    "test_X = TestX\n",
    "test_Y = TestY\n",
    "\n",
    "##### TODO #####\n",
    "#\n",
    "# Construct graph for each partition\n",
    "#\n",
    "train_edge_indices = Train_edges_list\n",
    "valid_edge_indices = Valid_edges_list\n",
    "test_edge_indices = Test_edges_list\n",
    "# Training\n",
    "var = Variables()\n",
    "opt_var = Container().copy([var.training, var.checkpointing])\n",
    "opt_var.mbatch_size = 512\n",
    "opt_var.lr = 1e-3\n",
    "opt_var.n_epochs = 5000\n",
    "opt_var.optimizer = 'Adam'\n",
    "opt_var.lr_decay = 1e-2\n",
    "\n",
    "\n",
    "##### TODO #####\n",
    "#\n",
    "# Compute and plug-in your loss weights here\n",
    "#\n",
    "loss_weights_train_torch = torch.ones(loss_weights_train_torch.shape,device='cuda')\n",
    "loss_weights_test_torch = torch.ones(loss_weights_test_torch.shape,device='cuda')\n",
    "loss_weights_valid_torch = torch.ones(loss_weights_valid_torch.shape,device='cuda')\n",
    "\n",
    "\n",
    "\n",
    "opt_var.set(\"loss_weights\",loss_weights_train_torch, \"train\")\n",
    "opt_var.set(\"loss_weights\", loss_weights_valid_torch, \"valid\")\n",
    "opt_var.set(\"loss_weights\", loss_weights_test_torch, \"test\")\n",
    "print(opt_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "uVltfO2b3FWo",
    "outputId": "e76c530a-dff2-47e0-fa25-f58f6ea2f74b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_edge_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-df59cd491f60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"X\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Y\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"edge_indices\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_edge_indices\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mvalid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"X\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalid_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Y\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalid_Y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"edge_indices\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalid_edge_indices\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"X\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Y\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"edge_indices\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest_edge_indices\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m##### MODEL #####\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLPGNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_edge_indices' is not defined"
     ]
    }
   ],
   "source": [
    "train = {\"X\": train_X, \"Y\": train_Y[:,None], \"edge_indices\": train_edge_indices}\n",
    "valid = {\"X\": valid_X, \"Y\": valid_Y[:,None], \"edge_indices\": valid_edge_indices}\n",
    "test = {\"X\": test_X, \"Y\": test_Y[:,None], \"edge_indices\": test_edge_indices}\n",
    "##### MODEL #####\n",
    "model = MLPGNN(80, 1, 16)\n",
    "model.optimize(train, valid, test, opt_var)\n",
    "# Prediction\n",
    "model, test = model.prepare(test, opt_var.use_gpu)\n",
    "preds = model.forward(test)[\"Yhat\"]\n",
    "print(preds.shape)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-462b41d41376>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Yhat\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model, test = model.prepare(test, opt_var.use_gpu)\n",
    "preds = model.forward(test)[\"Yhat\"]\n",
    "print(preds.shape)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-57c40e7b6876>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "preds = preds.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-ef8efe5a92cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(preds).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1904.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.022759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.040632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.004444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.008889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.022222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.453333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  1904.000000\n",
       "mean      0.022759\n",
       "std       0.040632\n",
       "min       0.000000\n",
       "25%       0.004444\n",
       "50%       0.008889\n",
       "75%       0.022222\n",
       "max       0.453333"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_Y).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-edd7153391a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mTestY_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mTEST_preds_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mTestY_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTestY_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mTEST_preds_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTEST_preds_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "TestY_final = scaler_2.inverse_transform(test_Y.reshape(-1,1))\n",
    "TEST_preds_final = scaler_2.inverse_transform(preds.reshape(-1,1))\n",
    "TestY_final = TestY_final.reshape(-1)\n",
    "TEST_preds_final = TEST_preds_final.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1904.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.120798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.142195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>102.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  1904.000000\n",
       "mean      5.120798\n",
       "std       9.142195\n",
       "min       0.000000\n",
       "25%       1.000000\n",
       "50%       2.000000\n",
       "75%       5.000000\n",
       "max     102.000000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(TestY_final).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TEST_preds_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-097c163937c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTEST_preds_final\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'TEST_preds_final' is not defined"
     ]
    }
   ],
   "source": [
    "TEST_preds_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TEST_preds_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-d5b5d8cb702f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTEST_preds_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mTEST_preds_final\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mTEST_preds_final\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TEST_preds_final' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(TEST_preds_final.shape[0]):\n",
    "    if TEST_preds_final[i] < 0:\n",
    "        TEST_preds_final[i] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TEST_preds_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-549280d62d08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_pts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTEST_preds_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'TEST_preds_final' is not defined"
     ]
    }
   ],
   "source": [
    "x_pts = np.arange(0,TEST_preds_final.shape[0] ,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_pts,TestY_final,TEST_preds_final)\n",
    "plt.legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestY_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_preds_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TEST_preds_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-6b7ecf221511>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mTestY_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTestY_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mTEST_preds_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTEST_preds_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The shape of the test predictions\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTEST_preds_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The shape of the True values of test\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTestY_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The shape of the ML-model prediction values of Y\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTest_old_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TEST_preds_final' is not defined"
     ]
    }
   ],
   "source": [
    "TestY_final = TestY_final.reshape(-1)\n",
    "TEST_preds_final = TEST_preds_final.reshape(-1)\n",
    "print(\"The shape of the test predictions\",TEST_preds_final.shape)\n",
    "print(\"The shape of the True values of test\",TestY_final.shape)\n",
    "print(\"The shape of the ML-model prediction values of Y\",Test_old_pred.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL_binary_right_predition = 0\n",
    "DL_binary_wrong_predition = 0\n",
    "dl_threshold = 10\n",
    "for i in range(TEST_preds_final.shape[0]):\n",
    "    if ((TEST_preds_final[i] >= dl_threshold and TestY_final[i] >= 10) or (TEST_preds_final[i] < dl_threshold and TestY_final[i] < 10)):\n",
    "        DL_binary_right_predition+=1\n",
    "    else:\n",
    "        DL_binary_wrong_predition+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Prediction \", \"True\") \n",
    "for i in range(TEST_preds_final.shape[0]):\n",
    "    if not ((TEST_preds_final[i] >= dl_threshold and TestY_final[i] >= 10) or (TEST_preds_final[i] < dl_threshold and TestY_final[i] < 10)):\n",
    "        if (TEST_preds_final[i]-TestY_final[i] > 10):\n",
    "            print(TEST_preds_final[i],\"  \",TestY_final[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DL_binary_right_predition' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-d74c5fb3d75e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdl_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDL_binary_right_predition\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mTestY_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Deep learning accuracy is:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DL_binary_right_predition' is not defined"
     ]
    }
   ],
   "source": [
    "dl_acc = DL_binary_right_predition/TestY_final.shape[0] * 100\n",
    "print(\"Deep learning accuracy is:\", dl_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TEST_preds_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-cdb80bf2f763>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mML_binary_wrong_predition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mml_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTEST_preds_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTest_old_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mml_threshold\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mTestY_final\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTest_old_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mml_threshold\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mTestY_final\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mML_binary_right_predition\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TEST_preds_final' is not defined"
     ]
    }
   ],
   "source": [
    "ML_binary_right_predition = 0\n",
    "ML_binary_wrong_predition = 0\n",
    "ml_threshold = 0.5\n",
    "for i in range(TEST_preds_final.shape[0]):\n",
    "    if ((Test_old_pred[i] >= ml_threshold and TestY_final[i] > 10) or (Test_old_pred[i] < ml_threshold and TestY_final[i] < 10)):\n",
    "        ML_binary_right_predition+=1\n",
    "    else:\n",
    "        ML_binary_wrong_predition+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning accuracy is: 0.0\n"
     ]
    }
   ],
   "source": [
    "ml_acc = ML_binary_right_predition/TestY_final.shape[0] * 100\n",
    "print(\"Machine learning accuracy is:\",ml_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TEST_preds_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-4926b5c3debe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTEST_preds_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTEST_preds_final\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mdl_threshold\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mTestY_final\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TEST_preds_final' is not defined"
     ]
    }
   ],
   "source": [
    "DL_true_positive = 0\n",
    "DL_true_negative = 0\n",
    "DL_false_positive = 0\n",
    "DL_false_negative = 0\n",
    "dl_threshold = 10\n",
    "\n",
    "\n",
    "for i in range(TEST_preds_final.shape[0]):\n",
    "    \n",
    "    if (TEST_preds_final[i] >= dl_threshold and TestY_final[i] >= 10): \n",
    "        DL_true_positive+=1\n",
    "    \n",
    "    elif (TEST_preds_final[i] < dl_threshold and TestY_final[i] < 10):\n",
    "        DL_true_negative+=1\n",
    "        \n",
    "    elif (TEST_preds_final[i] >= dl_threshold and TestY_final[i] < 10):\n",
    "        DL_false_positive+=1\n",
    "        \n",
    "    else:\n",
    "        DL_false_negative+=1\n",
    "        \n",
    "DL_true_positive = DL_true_positive/TestY_final.shape[0] * 100\n",
    "DL_true_negative = DL_true_negative/TestY_final.shape[0] * 100\n",
    "DL_false_positive = DL_false_positive/TestY_final.shape[0] * 100\n",
    "DL_false_negative = DL_false_negative/TestY_final.shape[0] * 100\n",
    "DL_false_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TEST_preds_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-d4a851334a6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mml_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTEST_preds_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTest_old_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mml_threshold\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mTestY_final\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TEST_preds_final' is not defined"
     ]
    }
   ],
   "source": [
    "ML_true_positive = 0\n",
    "ML_true_negative = 0\n",
    "ML_false_positive = 0\n",
    "ML_false_negative = 0\n",
    "ml_threshold = 0.5\n",
    "\n",
    "for i in range(TEST_preds_final.shape[0]):\n",
    "    \n",
    "    if (Test_old_pred[i] >= ml_threshold and TestY_final[i] >= 10): \n",
    "        ML_true_positive+=1\n",
    "    \n",
    "    elif (Test_old_pred[i] < ml_threshold and TestY_final[i] < 10):\n",
    "        ML_true_negative+=1\n",
    "        \n",
    "    elif (Test_old_pred[i] >= ml_threshold and TestY_final[i] < 10):\n",
    "        ML_false_positive+=1\n",
    "\n",
    "    else:\n",
    "        ML_false_negative+=1\n",
    "        \n",
    "ML_true_positive = ML_true_positive/TestY_final.shape[0] * 100\n",
    "ML_true_negative = ML_true_negative/TestY_final.shape[0] * 100\n",
    "ML_false_positive = ML_false_positive/TestY_final.shape[0] * 100\n",
    "ML_false_negative = ML_false_negative/TestY_final.shape[0] * 100\n",
    "ML_false_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_false_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dl_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-5f3c2b09c5a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Accurate'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Inaccurate'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'TP'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'TN'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'FP'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'FN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdl_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdl_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDL_true_positive\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDL_true_negative\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDL_false_positive\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDL_false_negative\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mml_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mml_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mML_true_positive\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mML_true_negative\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mML_false_positive\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mML_false_negative\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dl_acc' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "  \n",
    "X = ['Accurate', 'Inaccurate' , 'TP','TN','FP','FN']\n",
    "dl = [dl_acc, (100 - dl_acc), DL_true_positive,DL_true_negative,DL_false_positive,DL_false_negative]\n",
    "ml = [ml_acc, (100 - ml_acc), ML_true_positive,ML_true_negative,ML_false_positive,ML_false_negative]\n",
    "  \n",
    "X_axis = np.arange(len(X))\n",
    "  \n",
    "plt.bar(X_axis - 0.1, dl, 0.2, label = 'Deep learning model')\n",
    "plt.bar(X_axis + 0.1, ml, 0.2, label = 'Machine learning model')\n",
    "  \n",
    "plt.xticks(X_axis, X)\n",
    "plt.xlabel(\"Evaluation metrics\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "pbWozctM3FWo"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TEST_preds_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-5f95f4babd43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mDL_above_100\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTEST_preds_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TEST_preds_final' is not defined"
     ]
    }
   ],
   "source": [
    "DL_0_to_10 = 0\n",
    "DL_10_to_25 = 0\n",
    "DL_25_to_50 = 0\n",
    "DL_50_to_100 = 0\n",
    "DL_above_100 = 0\n",
    "\n",
    "for i in range(TEST_preds_final.shape[0]):\n",
    "    \n",
    "    \n",
    "    if (0  <= TEST_preds_final[i] <= 10 and 0 <= TestY_final[i] <= 10):\n",
    "        DL_0_to_10+=1\n",
    "    \n",
    "    elif (10 < TEST_preds_final[i] <= 25 and 10 < TestY_final[i] <= 25): \n",
    "        DL_10_to_25+=1\n",
    "    \n",
    "    elif (25 < TEST_preds_final[i] <= 50 and 25 < TestY_final[i] <= 50):\n",
    "        DL_25_to_50+=1\n",
    "        \n",
    "    elif(50 < TEST_preds_final[i] <= 100 and 50 < TestY_final[i] <= 100):\n",
    "        DL_50_to_100+=1\n",
    "        \n",
    "    elif((100 < TEST_preds_final[i] and 100 < TestY_final[i])):\n",
    "        DL_above_100+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "39BQuV3D3FWo"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TEST_preds_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-5fc3c34cae37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mDL_0_to_10\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mDL_10_to_25\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mDL_25_to_50\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mDL_50_to_100\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mDL_above_100\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mTEST_preds_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'TEST_preds_final' is not defined"
     ]
    }
   ],
   "source": [
    "(DL_0_to_10 + DL_10_to_25 + DL_25_to_50 + DL_50_to_100 + DL_above_100) / TEST_preds_final.shape[0] * 100"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
