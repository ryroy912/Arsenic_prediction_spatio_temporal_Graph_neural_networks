{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Arsenic_GNN_3.1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "!pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMKg0dQeE9Xy",
        "outputId": "215a35c8-68e8-412b-e26e-bd0403b5f766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.0+cu113\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.12.0+cu113.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_sparse-0.6.14-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 36.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-sparse, torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9 torch-sparse-0.6.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Sk4t5fSMu7r",
        "outputId": "cf22e7e9-3eba-403c-9e0b-326ece5596a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: torch==1.12.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.12.0+cu113)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/pyg-team/pytorch_geometric.git#egg=torch-geometric[full]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ur3iGbXDOOo0",
        "outputId": "db42173d-f324-4f16-948d-dd93325b1596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric[full]\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-install-_xaih609/torch-geometric_a5ed7534868b45e99146ff3944a2e99e\n",
            "  Running command git clone -q https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-install-_xaih609/torch-geometric_a5ed7534868b45e99146ff3944a2e99e\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric[full]) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric[full]) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric[full]) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric[full]) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric[full]) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric[full]) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric[full]) (1.0.2)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting hydra-core\n",
            "  Downloading hydra_core-1.2.0-py3-none-any.whl (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<4.21 in /usr/local/lib/python3.7/dist-packages (from torch-geometric[full]) (3.17.3)\n",
            "Collecting pytorch-lightning==1.6.*\n",
            "  Downloading pytorch_lightning-1.6.5-py3-none-any.whl (585 kB)\n",
            "\u001b[K     |████████████████████████████████| 585 kB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from torch-geometric[full]) (3.1.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from torch-geometric[full]) (0.56.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from torch-geometric[full]) (1.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric[full]) (1.3.5)\n",
            "Collecting captum\n",
            "  Downloading captum-0.5.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 45.2 MB/s \n",
            "\u001b[?25hCollecting rdflib\n",
            "  Downloading rdflib-6.2.0-py3-none-any.whl (500 kB)\n",
            "\u001b[K     |████████████████████████████████| 500 kB 48.9 MB/s \n",
            "\u001b[?25hCollecting trimesh\n",
            "  Downloading trimesh-3.13.1-py3-none-any.whl (660 kB)\n",
            "\u001b[K     |████████████████████████████████| 660 kB 44.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric[full]) (2.6.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from torch-geometric[full]) (0.8.10)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from torch-geometric[full]) (3.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from torch-geometric[full]) (0.18.3)\n",
            "Collecting pytorch-memlab\n",
            "  Downloading pytorch_memlab-0.2.4.tar.gz (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting torchmetrics>=0.7\n",
            "  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 45.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.*->torch-geometric[full]) (2.8.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.*->torch-geometric[full]) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.*->torch-geometric[full]) (4.1.1)\n",
            "Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.*->torch-geometric[full]) (1.12.0+cu113)\n",
            "Collecting PyYAML>=5.4\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 41.2 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 46.1 MB/s \n",
            "\u001b[?25hCollecting pyDeprecate>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->torch-geometric[full]) (3.8.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<4.21->torch-geometric[full]) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->torch-geometric[full]) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->torch-geometric[full]) (1.8.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->torch-geometric[full]) (1.47.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->torch-geometric[full]) (1.2.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->torch-geometric[full]) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->torch-geometric[full]) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->torch-geometric[full]) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->torch-geometric[full]) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->torch-geometric[full]) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->torch-geometric[full]) (3.4.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.*->torch-geometric[full]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.*->torch-geometric[full]) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.*->torch-geometric[full]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.*->torch-geometric[full]) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.*->torch-geometric[full]) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.*->torch-geometric[full]) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.*->torch-geometric[full]) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric[full]) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric[full]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric[full]) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric[full]) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.*->torch-geometric[full]) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->torch-geometric[full]) (2.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->torch-geometric[full]) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->torch-geometric[full]) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->torch-geometric[full]) (1.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->torch-geometric[full]) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->torch-geometric[full]) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->torch-geometric[full]) (1.8.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->torch-geometric[full]) (4.0.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->torch-geometric[full]) (1.5.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core->torch-geometric[full]) (5.9.0)\n",
            "Collecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 47.0 MB/s \n",
            "\u001b[?25hCollecting omegaconf~=2.2\n",
            "  Downloading omegaconf-2.2.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric[full]) (2.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-geometric[full]) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-geometric[full]) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-geometric[full]) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba->torch-geometric[full]) (0.39.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric[full]) (2022.1)\n",
            "Collecting calmsize\n",
            "  Downloading calmsize-0.1.3.tar.gz (3.7 kB)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 262 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->torch-geometric[full]) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->torch-geometric[full]) (1.3.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->torch-geometric[full]) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->torch-geometric[full]) (2021.11.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric[full]) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric[full]) (1.1.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->torch-geometric[full]) (1.2.1)\n",
            "Building wheels for collected packages: torch-geometric, antlr4-python3-runtime, pytorch-memlab, calmsize\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.1.0-py3-none-any.whl size=686178 sha256=bc265411bf33eb60504918a40a2b0a36f71f7e9e6c32e2249eed5be080a7b86f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6f8k8gt4/wheels/85/c9/07/7936efecad79b906348a7e9fb644d914160544efa9aa7f4b2b\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=b9ae94fe90cf0385d3e2ec172723ea688d22cd49934f62f32eaf194c30a78ef5\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n",
            "  Building wheel for pytorch-memlab (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-memlab: filename=pytorch_memlab-0.2.4-py3-none-any.whl size=22855 sha256=cf022859ea478302ca9f596160e128718b595f0959ceabff27d99a26f0307886\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/c4/8e/64b321e10754783fb334f883d21b651860ee0737ffdbf688c7\n",
            "  Building wheel for calmsize (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for calmsize: filename=calmsize-0.1.3-py3-none-any.whl size=2887 sha256=e4bcbf0aa7e76896e1b023e2133133deacac1493c7d0f7a42ca86c15a55f2759\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/92/5f/c4c4e3fa257084aecbdc44c0fe60bdef0cb870603f3642dd96\n",
            "Successfully built torch-geometric antlr4-python3-runtime pytorch-memlab calmsize\n",
            "Installing collected packages: PyYAML, fsspec, antlr4-python3-runtime, torchmetrics, pyDeprecate, omegaconf, isodate, calmsize, yacs, trimesh, torch-geometric, rdflib, pytorch-memlab, pytorch-lightning, hydra-core, captum\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 antlr4-python3-runtime-4.9.3 calmsize-0.1.3 captum-0.5.0 fsspec-2022.7.1 hydra-core-1.2.0 isodate-0.6.1 omegaconf-2.2.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.5 pytorch-memlab-0.2.4 rdflib-6.2.0 torch-geometric-2.1.0 torchmetrics-0.9.3 trimesh-3.13.1 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import ipywidgets as widgets \n",
        "from IPython.display import display \n",
        "import pylab\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import sklearn\n",
        "import keras.layers as kl\n",
        "from numpy import genfromtxt\n",
        "from numpy import asarray\n",
        "from numpy import savetxt\n",
        "import networkx as nx\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import SAGEConv\n",
        "from torch_geometric.nn import GCN"
      ],
      "metadata": {
        "id": "kIfCQDCoLVgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import InMemoryDataset, Data, download_url, extract_zip"
      ],
      "metadata": {
        "id": "UELLwgbMAtSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df_arsenic_prelim = pd.read_csv (r'drive/My Drive/Colab Notebooks/as.csv')\n",
        "correlation_matrix_recovered = genfromtxt('drive/My Drive/Colab Notebooks/PC.csv',delimiter=',')\n",
        "euclidean_matrix_recovered = genfromtxt('drive/My Drive/Colab Notebooks/ED.csv',delimiter=',')"
      ],
      "metadata": {
        "id": "0QoIcO-N24cA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_arsenic_prelim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "5ZdchL013hx3",
        "outputId": "5ca05889-6381-49cf-9463-6e053ad95606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       SiteID    As  X_Albers   Y_Albers   WellDepth  AvgAnnualN_CAFO_1992_97  \\\n",
              "0           1   6.0  924000.0  2006000.0  105.912831                16.678065   \n",
              "1           2   1.0  892000.0  2080000.0   54.861323                 7.688502   \n",
              "2           3  13.0  886000.0  2066000.0   34.745504                 6.245885   \n",
              "3           4   1.0  898000.0  2076000.0   59.737885                 4.900404   \n",
              "4           5   2.0  896000.0  2062000.0   45.717769                 6.511748   \n",
              "...       ...   ...       ...        ...         ...                      ...   \n",
              "9996     9997   0.0  536000.0  2390000.0   35.964645                 3.949343   \n",
              "9997     9998   1.0  610000.0  2484000.0   19.506248                 8.030330   \n",
              "9998     9999   6.0  616000.0  2526000.0   24.992380                 0.158934   \n",
              "9999    10000   0.0  602000.0  2586000.0   26.211521                 0.004975   \n",
              "10000   10001   0.0  668000.0  2620000.0   12.496190                 0.028986   \n",
              "\n",
              "       AvgAnnualN_Fert_1992_2001       AWC     AWS25   BFI  ...   Transmiss  \\\n",
              "0                      48.483771  0.141277  5.384314  21.0  ...  143.362904   \n",
              "1                      50.638261  0.217775  7.311919  37.0  ...  137.152244   \n",
              "2                      43.503552  0.140200  5.400000  33.0  ...  121.646066   \n",
              "3                      34.132068  0.154753  5.318469  37.0  ...  298.232568   \n",
              "4                      45.355325  0.140200  5.400000  28.0  ...   97.123320   \n",
              "...                          ...       ...       ...   ...  ...         ...   \n",
              "9996                   11.546021  0.082813  2.720000  74.0  ...   54.346575   \n",
              "9997                   10.843744  0.159466  4.090000  59.0  ...  115.224598   \n",
              "9998                    0.199489  0.126106  4.030000  63.0  ...   40.882361   \n",
              "9999                    0.015434  0.126106  4.030000  66.0  ...   59.112810   \n",
              "10000                   0.058744  0.066700  2.000000  62.0  ...   59.639661   \n",
              "\n",
              "             TWI        VRT       VWC  YngWtrMeanAge  YngWtrMeanAge_VertMean  \\\n",
              "0       9.902970   5.956547  0.304000      23.158235               17.689265   \n",
              "1       9.067347   4.196766  0.343552      22.015855               17.739371   \n",
              "2      11.470297  17.558480  0.270166      17.762669               15.950136   \n",
              "3       9.815662   1.231952  0.328985      27.709500               17.589893   \n",
              "4       9.435353  21.539828  0.268193      19.238581               14.557619   \n",
              "...          ...        ...       ...            ...                     ...   \n",
              "9996    8.505940   6.354813  0.160139      14.421028               10.310266   \n",
              "9997   13.790910   0.416030  0.344196       8.765928               16.686542   \n",
              "9998   11.154347   1.048951  0.253424      15.627269               11.281490   \n",
              "9999   13.113131   0.520421  0.280687      21.815356               15.832110   \n",
              "10000  12.550000   0.098656  0.367925       5.079691               14.141643   \n",
              "\n",
              "             DTW   Data  as10  Pred  \n",
              "0       3.082386  train   0.0  0.00  \n",
              "1       3.076582  train   0.0  0.06  \n",
              "2       5.645093  train   1.0  0.83  \n",
              "3       1.044807  train   0.0  0.03  \n",
              "4       8.535328  train   0.0  0.01  \n",
              "...          ...    ...   ...   ...  \n",
              "9996   11.500084   test   0.0  0.00  \n",
              "9997    0.188501   test   0.0  0.11  \n",
              "9998    1.518130   test   0.0  0.01  \n",
              "9999    0.643534   test   0.0  0.05  \n",
              "10000   0.114506   test   0.0  0.01  \n",
              "\n",
              "[7616 rows x 87 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-131ebdd7-1a03-416f-8fb5-48ef12b9fae5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SiteID</th>\n",
              "      <th>As</th>\n",
              "      <th>X_Albers</th>\n",
              "      <th>Y_Albers</th>\n",
              "      <th>WellDepth</th>\n",
              "      <th>AvgAnnualN_CAFO_1992_97</th>\n",
              "      <th>AvgAnnualN_Fert_1992_2001</th>\n",
              "      <th>AWC</th>\n",
              "      <th>AWS25</th>\n",
              "      <th>BFI</th>\n",
              "      <th>...</th>\n",
              "      <th>Transmiss</th>\n",
              "      <th>TWI</th>\n",
              "      <th>VRT</th>\n",
              "      <th>VWC</th>\n",
              "      <th>YngWtrMeanAge</th>\n",
              "      <th>YngWtrMeanAge_VertMean</th>\n",
              "      <th>DTW</th>\n",
              "      <th>Data</th>\n",
              "      <th>as10</th>\n",
              "      <th>Pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>924000.0</td>\n",
              "      <td>2006000.0</td>\n",
              "      <td>105.912831</td>\n",
              "      <td>16.678065</td>\n",
              "      <td>48.483771</td>\n",
              "      <td>0.141277</td>\n",
              "      <td>5.384314</td>\n",
              "      <td>21.0</td>\n",
              "      <td>...</td>\n",
              "      <td>143.362904</td>\n",
              "      <td>9.902970</td>\n",
              "      <td>5.956547</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>23.158235</td>\n",
              "      <td>17.689265</td>\n",
              "      <td>3.082386</td>\n",
              "      <td>train</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>892000.0</td>\n",
              "      <td>2080000.0</td>\n",
              "      <td>54.861323</td>\n",
              "      <td>7.688502</td>\n",
              "      <td>50.638261</td>\n",
              "      <td>0.217775</td>\n",
              "      <td>7.311919</td>\n",
              "      <td>37.0</td>\n",
              "      <td>...</td>\n",
              "      <td>137.152244</td>\n",
              "      <td>9.067347</td>\n",
              "      <td>4.196766</td>\n",
              "      <td>0.343552</td>\n",
              "      <td>22.015855</td>\n",
              "      <td>17.739371</td>\n",
              "      <td>3.076582</td>\n",
              "      <td>train</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>13.0</td>\n",
              "      <td>886000.0</td>\n",
              "      <td>2066000.0</td>\n",
              "      <td>34.745504</td>\n",
              "      <td>6.245885</td>\n",
              "      <td>43.503552</td>\n",
              "      <td>0.140200</td>\n",
              "      <td>5.400000</td>\n",
              "      <td>33.0</td>\n",
              "      <td>...</td>\n",
              "      <td>121.646066</td>\n",
              "      <td>11.470297</td>\n",
              "      <td>17.558480</td>\n",
              "      <td>0.270166</td>\n",
              "      <td>17.762669</td>\n",
              "      <td>15.950136</td>\n",
              "      <td>5.645093</td>\n",
              "      <td>train</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>898000.0</td>\n",
              "      <td>2076000.0</td>\n",
              "      <td>59.737885</td>\n",
              "      <td>4.900404</td>\n",
              "      <td>34.132068</td>\n",
              "      <td>0.154753</td>\n",
              "      <td>5.318469</td>\n",
              "      <td>37.0</td>\n",
              "      <td>...</td>\n",
              "      <td>298.232568</td>\n",
              "      <td>9.815662</td>\n",
              "      <td>1.231952</td>\n",
              "      <td>0.328985</td>\n",
              "      <td>27.709500</td>\n",
              "      <td>17.589893</td>\n",
              "      <td>1.044807</td>\n",
              "      <td>train</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>896000.0</td>\n",
              "      <td>2062000.0</td>\n",
              "      <td>45.717769</td>\n",
              "      <td>6.511748</td>\n",
              "      <td>45.355325</td>\n",
              "      <td>0.140200</td>\n",
              "      <td>5.400000</td>\n",
              "      <td>28.0</td>\n",
              "      <td>...</td>\n",
              "      <td>97.123320</td>\n",
              "      <td>9.435353</td>\n",
              "      <td>21.539828</td>\n",
              "      <td>0.268193</td>\n",
              "      <td>19.238581</td>\n",
              "      <td>14.557619</td>\n",
              "      <td>8.535328</td>\n",
              "      <td>train</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>9997</td>\n",
              "      <td>0.0</td>\n",
              "      <td>536000.0</td>\n",
              "      <td>2390000.0</td>\n",
              "      <td>35.964645</td>\n",
              "      <td>3.949343</td>\n",
              "      <td>11.546021</td>\n",
              "      <td>0.082813</td>\n",
              "      <td>2.720000</td>\n",
              "      <td>74.0</td>\n",
              "      <td>...</td>\n",
              "      <td>54.346575</td>\n",
              "      <td>8.505940</td>\n",
              "      <td>6.354813</td>\n",
              "      <td>0.160139</td>\n",
              "      <td>14.421028</td>\n",
              "      <td>10.310266</td>\n",
              "      <td>11.500084</td>\n",
              "      <td>test</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>9998</td>\n",
              "      <td>1.0</td>\n",
              "      <td>610000.0</td>\n",
              "      <td>2484000.0</td>\n",
              "      <td>19.506248</td>\n",
              "      <td>8.030330</td>\n",
              "      <td>10.843744</td>\n",
              "      <td>0.159466</td>\n",
              "      <td>4.090000</td>\n",
              "      <td>59.0</td>\n",
              "      <td>...</td>\n",
              "      <td>115.224598</td>\n",
              "      <td>13.790910</td>\n",
              "      <td>0.416030</td>\n",
              "      <td>0.344196</td>\n",
              "      <td>8.765928</td>\n",
              "      <td>16.686542</td>\n",
              "      <td>0.188501</td>\n",
              "      <td>test</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>9999</td>\n",
              "      <td>6.0</td>\n",
              "      <td>616000.0</td>\n",
              "      <td>2526000.0</td>\n",
              "      <td>24.992380</td>\n",
              "      <td>0.158934</td>\n",
              "      <td>0.199489</td>\n",
              "      <td>0.126106</td>\n",
              "      <td>4.030000</td>\n",
              "      <td>63.0</td>\n",
              "      <td>...</td>\n",
              "      <td>40.882361</td>\n",
              "      <td>11.154347</td>\n",
              "      <td>1.048951</td>\n",
              "      <td>0.253424</td>\n",
              "      <td>15.627269</td>\n",
              "      <td>11.281490</td>\n",
              "      <td>1.518130</td>\n",
              "      <td>test</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>10000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>602000.0</td>\n",
              "      <td>2586000.0</td>\n",
              "      <td>26.211521</td>\n",
              "      <td>0.004975</td>\n",
              "      <td>0.015434</td>\n",
              "      <td>0.126106</td>\n",
              "      <td>4.030000</td>\n",
              "      <td>66.0</td>\n",
              "      <td>...</td>\n",
              "      <td>59.112810</td>\n",
              "      <td>13.113131</td>\n",
              "      <td>0.520421</td>\n",
              "      <td>0.280687</td>\n",
              "      <td>21.815356</td>\n",
              "      <td>15.832110</td>\n",
              "      <td>0.643534</td>\n",
              "      <td>test</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10000</th>\n",
              "      <td>10001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>668000.0</td>\n",
              "      <td>2620000.0</td>\n",
              "      <td>12.496190</td>\n",
              "      <td>0.028986</td>\n",
              "      <td>0.058744</td>\n",
              "      <td>0.066700</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>62.0</td>\n",
              "      <td>...</td>\n",
              "      <td>59.639661</td>\n",
              "      <td>12.550000</td>\n",
              "      <td>0.098656</td>\n",
              "      <td>0.367925</td>\n",
              "      <td>5.079691</td>\n",
              "      <td>14.141643</td>\n",
              "      <td>0.114506</td>\n",
              "      <td>test</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7616 rows × 87 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-131ebdd7-1a03-416f-8fb5-48ef12b9fae5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-131ebdd7-1a03-416f-8fb5-48ef12b9fae5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-131ebdd7-1a03-416f-8fb5-48ef12b9fae5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_arsenic_prelim.isnull().values.any()\n",
        "df_arsenic_prelim.isnull().sum()\n",
        "df_arsenic_prelim = df_arsenic_prelim.dropna()"
      ],
      "metadata": {
        "id": "n2k0O-6Q3hz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_arsenic_prelim.iloc[:,4:-3]\n",
        "Y_TRUE = df_arsenic_prelim.iloc[:,1]\n",
        "Y_PRED_BIN = df_arsenic_prelim.iloc[:,-2]\n",
        "Y_PRED_CONTINUOUS = df_arsenic_prelim.iloc[:,-1]"
      ],
      "metadata": {
        "id": "oU3izz2v3h2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mockx= np.array(X)\n",
        "mocky= np.array(Y_TRUE)\n",
        "print(\"Shape of mockx\",mockx.shape)\n",
        "print(\"Shape of mockx\",mocky.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jim5Pu5I3h6m",
        "outputId": "23fa8d6e-a2c7-41e6-ed22-40342c08cb9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of mockx (7616, 80)\n",
            "Shape of mockx (7616,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6.,  1., 13., ...,  6.,  0.,  0.])"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_x = torch.from_numpy(mockx)\n",
        "tensor_y = torch.from_numpy(mocky)\n",
        "tensor_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnofmC9F3szp",
        "outputId": "37e4e289-3644-4daa-cb3c-66495110899f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 6.,  1., 13.,  ...,  6.,  0.,  0.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mask = np.ones(7616)\n",
        "test_mask = np.zeros(7616)\n",
        "val_mask = np.zeros(7616)\n",
        "tensor_train_mask = torch.tensor(train_mask, dtype=torch.long)\n",
        "tensor_val_mask = torch.tensor(val_mask, dtype=torch.long)\n",
        "tensor_test_mask = torch.tensor(test_mask, dtype=torch.long)"
      ],
      "metadata": {
        "id": "8noWoEmy3s14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"the Minimum Euclidean distance obtained is: \",np.min(euclidean_matrix_recovered))\n",
        "print(\"the Maximum Euclidean distance obtained is: \",np.max(euclidean_matrix_recovered))\n",
        "print(\"ED shape\",euclidean_matrix_recovered.shape)\n",
        "\n",
        "num=0\n",
        "x=y=7616\n",
        "cutoff_euclidean = 10000\n",
        "cutoff_correlation = 0.95\n",
        "Edge_matrix = np.zeros((x,y))\n",
        "Edge_matrix_coo = np.zeros((2,76811*2))\n",
        "\n",
        "for i in range(x):\n",
        "    for j in range(y):\n",
        "        if (i!=j) and (correlation_matrix_recovered[i,j] > cutoff_correlation or euclidean_matrix_recovered[i,j] < cutoff_euclidean):\n",
        "            Edge_matrix[i,j]=1\n",
        "            num+=1\n",
        "print(num)"
      ],
      "metadata": {
        "id": "TJh3y9UEaxRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.from_numpy_matrix(Edge_matrix)\n",
        "n = G.number_of_nodes()\n",
        "m = G.number_of_edges()\n",
        "print(m,n)\n",
        "\n",
        "edge_list = np.zeros((2,m))\n",
        "\n",
        "edge_list[0,:] = nx.to_pandas_edgelist(G)['source']\n",
        "edge_list[1,:] = nx.to_pandas_edgelist(G)['target']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdYZYSD7BIbP",
        "outputId": "bf9472e8-f3e2-4a50-e301-411efbf4b346"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10469 7616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#edge_list = torch.from_numpy(edge_list)\n",
        "edge_idx = torch.tensor(edge_list, dtype=torch.long)"
      ],
      "metadata": {
        "id": "QfLGFCB9BIdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Trial1data = Data(x=tensor_x,edge_index=edge_idx,y=tensor_y,train_mask=tensor_train_mask,val_mask=tensor_val_mask,test_mask=tensor_test_mask)"
      ],
      "metadata": {
        "id": "I3J7LoRmBIhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.y"
      ],
      "metadata": {
        "id": "hdbf_RdwJlF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Trial1data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdjBdWw6BIk9",
        "outputId": "cd98f93d-4539-46ad-f36f-723fd21bb1b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[7616, 80], edge_index=[2, 10469], y=[7616])"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global hidden_layer_dimension\n",
        "hidden_layer_dimension = 100\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # you can change convolutions here \n",
        "        #self.conv1 = GCN(80, hidden_layer_dimension,num_layers=5)\n",
        "        #self.conv2 = GCN(hidden_layer_dimension,10,num_layers=5)\n",
        "       \n",
        "        self.conv1 = GCNConv(dataset.num_node_features, hidden_layer_dimension)\n",
        "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
        "        self.dense = nn.LazyLinear(1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.selu(x)\n",
        "        #x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.selu(x)\n",
        "        x = self.dense(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "0B1fsp4YFAAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Net().to(device)\n",
        "data = Trial1data.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(10000):\n",
        "    optimizer.zero_grad()\n",
        "    data['x'] = data['x'].float()\n",
        "    out = model(data)\n",
        "    loss = F.mse_loss(out[data.train_mask], data.y[data.train_mask].float())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    pred = model(data)\n",
        "    #correct = float (pred[data.train_mask] - (data.y[data.train_mask]).sum())\n",
        "    #acc = correct / data.train_mask.sum().item()\n",
        "    print('Epoch: %d, mse: %.8f'%(epoch,loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NV1aJ9qD31WX",
        "outputId": "d1820255-a917-4108-8365-8ad65d1faf7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: Using a target size (torch.Size([7616])) that is different to the input size (torch.Size([7616, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, mse: 25315.61914062\n",
            "Epoch: 1, mse: 232932.00000000\n",
            "Epoch: 2, mse: 6907.81152344\n",
            "Epoch: 3, mse: 3944.78149414\n",
            "Epoch: 4, mse: 1323.22644043\n",
            "Epoch: 5, mse: 476.84317017\n",
            "Epoch: 6, mse: 3679.25000000\n",
            "Epoch: 7, mse: 6040.35595703\n",
            "Epoch: 8, mse: 3252.70849609\n",
            "Epoch: 9, mse: 821.44927979\n",
            "Epoch: 10, mse: 148.87403870\n",
            "Epoch: 11, mse: 5.14837551\n",
            "Epoch: 12, mse: 28.12781143\n",
            "Epoch: 13, mse: 98.60840607\n",
            "Epoch: 14, mse: 92.55858612\n",
            "Epoch: 15, mse: 231.21290588\n",
            "Epoch: 16, mse: 87.47313690\n",
            "Epoch: 17, mse: 148.87889099\n",
            "Epoch: 18, mse: 137.97668457\n",
            "Epoch: 19, mse: 61.26586533\n",
            "Epoch: 20, mse: 3.84344530\n",
            "Epoch: 21, mse: 1.86843896\n",
            "Epoch: 22, mse: 2646.43872070\n",
            "Epoch: 23, mse: 1.85079193\n",
            "Epoch: 24, mse: 0.60873789\n",
            "Epoch: 25, mse: 0.21480845\n",
            "Epoch: 26, mse: 2.25946045\n",
            "Epoch: 27, mse: 1.80438781\n",
            "Epoch: 28, mse: 1.90936494\n",
            "Epoch: 29, mse: 229.58888245\n",
            "Epoch: 30, mse: 1.77566791\n",
            "Epoch: 31, mse: 1.76637006\n",
            "Epoch: 32, mse: 1.75639093\n",
            "Epoch: 33, mse: 1.74583685\n",
            "Epoch: 34, mse: 1.73479974\n",
            "Epoch: 35, mse: 1.72335315\n",
            "Epoch: 36, mse: 1.71156311\n",
            "Epoch: 37, mse: 50.10839081\n",
            "Epoch: 38, mse: 1.68724847\n",
            "Epoch: 39, mse: 3.00469923\n",
            "Epoch: 40, mse: 23.59143257\n",
            "Epoch: 41, mse: 0.00014145\n",
            "Epoch: 42, mse: 1.64479828\n",
            "Epoch: 43, mse: 1.63533521\n",
            "Epoch: 44, mse: 1.62526715\n",
            "Epoch: 45, mse: 1.61470306\n",
            "Epoch: 46, mse: 1.60372913\n",
            "Epoch: 47, mse: 1.59240437\n",
            "Epoch: 48, mse: 1.58112299\n",
            "Epoch: 49, mse: 1.56958795\n",
            "Epoch: 50, mse: 1.55783081\n",
            "Epoch: 51, mse: 1.54588807\n",
            "Epoch: 52, mse: 1.53378773\n",
            "Epoch: 53, mse: 1.52156019\n",
            "Epoch: 54, mse: 1.50922418\n",
            "Epoch: 55, mse: 1.49680805\n",
            "Epoch: 56, mse: 1.48432910\n",
            "Epoch: 57, mse: 1.47180188\n",
            "Epoch: 58, mse: 1.45924091\n",
            "Epoch: 59, mse: 1.44666231\n",
            "Epoch: 60, mse: 1.43407512\n",
            "Epoch: 61, mse: 1.42149341\n",
            "Epoch: 62, mse: 1.40892112\n",
            "Epoch: 63, mse: 1.39637017\n",
            "Epoch: 64, mse: 1.38384688\n",
            "Epoch: 65, mse: 0.90194708\n",
            "Epoch: 66, mse: 171.43423462\n",
            "Epoch: 67, mse: 0.50264156\n",
            "Epoch: 68, mse: 1.36286998\n",
            "Epoch: 69, mse: 1.36339080\n",
            "Epoch: 70, mse: 1.36302173\n",
            "Epoch: 71, mse: 1.36185467\n",
            "Epoch: 72, mse: 1.35997295\n",
            "Epoch: 73, mse: 1.35744536\n",
            "Epoch: 74, mse: 1.35340118\n",
            "Epoch: 75, mse: 0.53827143\n",
            "Epoch: 76, mse: 1.34421110\n",
            "Epoch: 77, mse: 1.33910382\n",
            "Epoch: 78, mse: 1.33277118\n",
            "Epoch: 79, mse: 1.32524610\n",
            "Epoch: 80, mse: 1.31647480\n",
            "Epoch: 81, mse: 1.30671704\n",
            "Epoch: 82, mse: 1.29621065\n",
            "Epoch: 83, mse: 1.28357410\n",
            "Epoch: 84, mse: 1.26892507\n",
            "Epoch: 85, mse: 1.25219643\n",
            "Epoch: 86, mse: 1.23396719\n",
            "Epoch: 87, mse: 1.21694100\n",
            "Epoch: 88, mse: 1.19917595\n",
            "Epoch: 89, mse: 1.17981327\n",
            "Epoch: 90, mse: 1.15882421\n",
            "Epoch: 91, mse: 1.13619316\n",
            "Epoch: 92, mse: 1.11192620\n",
            "Epoch: 93, mse: 1.08604050\n",
            "Epoch: 94, mse: 1.05856979\n",
            "Epoch: 95, mse: 1.02956784\n",
            "Epoch: 96, mse: 0.99910080\n",
            "Epoch: 97, mse: 0.96724951\n",
            "Epoch: 98, mse: 0.93410760\n",
            "Epoch: 99, mse: 0.89978027\n",
            "Epoch: 100, mse: 0.86438626\n",
            "Epoch: 101, mse: 0.82805264\n",
            "Epoch: 102, mse: 0.79091781\n",
            "Epoch: 103, mse: 0.75312567\n",
            "Epoch: 104, mse: 0.61212736\n",
            "Epoch: 105, mse: 157.78569031\n",
            "Epoch: 106, mse: 0.21821086\n",
            "Epoch: 107, mse: 0.65090954\n",
            "Epoch: 108, mse: 0.63507038\n",
            "Epoch: 109, mse: 0.61719525\n",
            "Epoch: 110, mse: 0.59754229\n",
            "Epoch: 111, mse: 0.57635689\n",
            "Epoch: 112, mse: 0.55387300\n",
            "Epoch: 113, mse: 0.53031349\n",
            "Epoch: 114, mse: 0.50589174\n",
            "Epoch: 115, mse: 0.48081210\n",
            "Epoch: 116, mse: 0.45526829\n",
            "Epoch: 117, mse: 0.42944342\n",
            "Epoch: 118, mse: 0.40351227\n",
            "Epoch: 119, mse: 0.37763786\n",
            "Epoch: 120, mse: 0.35197383\n",
            "Epoch: 121, mse: 0.32666287\n",
            "Epoch: 122, mse: 0.30183774\n",
            "Epoch: 123, mse: 0.27761936\n",
            "Epoch: 124, mse: 0.25411895\n",
            "Epoch: 125, mse: 0.23143584\n",
            "Epoch: 126, mse: 0.20965861\n",
            "Epoch: 127, mse: 0.18886377\n",
            "Epoch: 128, mse: 0.16911784\n",
            "Epoch: 129, mse: 0.15047409\n",
            "Epoch: 130, mse: 0.13297594\n",
            "Epoch: 131, mse: 0.11665437\n",
            "Epoch: 132, mse: 0.10152913\n",
            "Epoch: 133, mse: 0.08760925\n",
            "Epoch: 134, mse: 0.07489227\n",
            "Epoch: 135, mse: 0.06336522\n",
            "Epoch: 136, mse: 0.05300514\n",
            "Epoch: 137, mse: 0.04377904\n",
            "Epoch: 138, mse: 0.03564516\n",
            "Epoch: 139, mse: 0.02855345\n",
            "Epoch: 140, mse: 0.02244671\n",
            "Epoch: 141, mse: 0.01726144\n",
            "Epoch: 142, mse: 0.01292878\n",
            "Epoch: 143, mse: 0.00937629\n",
            "Epoch: 144, mse: 0.00652855\n",
            "Epoch: 145, mse: 0.00430891\n",
            "Epoch: 146, mse: 0.00264073\n",
            "Epoch: 147, mse: 0.00144846\n",
            "Epoch: 148, mse: 0.00065896\n",
            "Epoch: 149, mse: 0.00020257\n",
            "Epoch: 150, mse: 0.00001407\n",
            "Epoch: 151, mse: 0.00003340\n",
            "Epoch: 152, mse: 0.00020636\n",
            "Epoch: 153, mse: 0.00048495\n",
            "Epoch: 154, mse: 0.00082768\n",
            "Epoch: 155, mse: 0.00119950\n",
            "Epoch: 156, mse: 0.00157176\n",
            "Epoch: 157, mse: 0.00192191\n",
            "Epoch: 158, mse: 0.00223304\n",
            "Epoch: 159, mse: 0.00249340\n",
            "Epoch: 160, mse: 0.00269582\n",
            "Epoch: 161, mse: 0.00283707\n",
            "Epoch: 162, mse: 0.00291720\n",
            "Epoch: 163, mse: 0.00293887\n",
            "Epoch: 164, mse: 0.00290680\n",
            "Epoch: 165, mse: 0.00282718\n",
            "Epoch: 166, mse: 0.00270711\n",
            "Epoch: 167, mse: 0.00255412\n",
            "Epoch: 168, mse: 0.00237593\n",
            "Epoch: 169, mse: 0.00217998\n",
            "Epoch: 170, mse: 0.00197327\n",
            "Epoch: 171, mse: 0.00176218\n",
            "Epoch: 172, mse: 0.00155226\n",
            "Epoch: 173, mse: 0.00134827\n",
            "Epoch: 174, mse: 0.00115409\n",
            "Epoch: 175, mse: 0.00097273\n",
            "Epoch: 176, mse: 0.00080638\n",
            "Epoch: 177, mse: 0.00065647\n",
            "Epoch: 178, mse: 0.00052378\n",
            "Epoch: 179, mse: 0.00040846\n",
            "Epoch: 180, mse: 0.00031017\n",
            "Epoch: 181, mse: 0.00022817\n",
            "Epoch: 182, mse: 0.00016141\n",
            "Epoch: 183, mse: 0.00010857\n",
            "Epoch: 184, mse: 0.00006823\n",
            "Epoch: 185, mse: 0.00003883\n",
            "Epoch: 186, mse: 0.00001883\n",
            "Epoch: 187, mse: 0.00000669\n",
            "Epoch: 188, mse: 0.00000095\n",
            "Epoch: 189, mse: 0.00000024\n",
            "Epoch: 190, mse: 0.00000331\n",
            "Epoch: 191, mse: 0.00000904\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-193-962622638b1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " _, pred = model(data).max(dim=1)\n",
        "correct = float (pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
        "acc = correct / data.test_mask.sum().item()\n",
        "print('Accuracy: {:.4f}'.format(acc))"
      ],
      "metadata": {
        "id": "-2HfiJx835-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV4Vmq7cVo0C",
        "outputId": "85baf1d6-b987-425b-cf87-b4bc6cfab751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9959],\n",
              "        [0.9959],\n",
              "        [0.9959],\n",
              "        ...,\n",
              "        [0.9959],\n",
              "        [0.9959],\n",
              "        [0.9959]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFTCZPGnWGje",
        "outputId": "b7217f07-3124-4b7d-d0ca-2a61256242be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 6.,  1., 13.,  ...,  6.,  0.,  0.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "as0IuRLT8AIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sizhg5uya26l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tkK7MPWZa289"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "evynHJc2a2_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ev-jwW2Da3Bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Net().to(device)\n",
        "data = Trial1data.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(10000):\n",
        "    optimizer.zero_grad()\n",
        "    data['x'] = data['x'].float()\n",
        "    out = model(data)\n",
        "    loss = F.mse_loss(out[data.train_mask], data.y[data.train_mask].float())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    pred = model(data)\n",
        "    #correct = float (pred[data.train_mask] - (data.y[data.train_mask]).sum())\n",
        "    #acc = correct / data.train_mask.sum().item()\n",
        "    print('Epoch: %d, mse: %.4f'%(epoch,loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qCAKqjl3a3FK",
        "outputId": "e91960ae-5ed2-4483-f434-1bb4a2fc7fbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: Using a target size (torch.Size([7616])) that is different to the input size (torch.Size([7616, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, mse: 170629.9062\n",
            "Epoch: 1, mse: 16118.3750\n",
            "Epoch: 2, mse: 86667.5156\n",
            "Epoch: 3, mse: 714.3786\n",
            "Epoch: 4, mse: 1.0964\n",
            "Epoch: 5, mse: 733.8629\n",
            "Epoch: 6, mse: 1.0444\n",
            "Epoch: 7, mse: 1.0215\n",
            "Epoch: 8, mse: 0.9999\n",
            "Epoch: 9, mse: 0.9787\n",
            "Epoch: 10, mse: 0.9579\n",
            "Epoch: 11, mse: 0.9375\n",
            "Epoch: 12, mse: 0.9171\n",
            "Epoch: 13, mse: 0.8968\n",
            "Epoch: 14, mse: 0.8764\n",
            "Epoch: 15, mse: 0.8556\n",
            "Epoch: 16, mse: 0.8347\n",
            "Epoch: 17, mse: 0.8135\n",
            "Epoch: 18, mse: 0.7919\n",
            "Epoch: 19, mse: 0.7700\n",
            "Epoch: 20, mse: 0.7477\n",
            "Epoch: 21, mse: 305.3626\n",
            "Epoch: 22, mse: 0.7031\n",
            "Epoch: 23, mse: 0.6811\n",
            "Epoch: 24, mse: 0.6589\n",
            "Epoch: 25, mse: 0.6363\n",
            "Epoch: 26, mse: 0.6133\n",
            "Epoch: 27, mse: 0.5898\n",
            "Epoch: 28, mse: 0.0598\n",
            "Epoch: 29, mse: 0.0565\n",
            "Epoch: 30, mse: 0.0567\n",
            "Epoch: 31, mse: 23.5726\n",
            "Epoch: 32, mse: 0.4916\n",
            "Epoch: 33, mse: 0.4760\n",
            "Epoch: 34, mse: 0.4591\n",
            "Epoch: 35, mse: 0.4412\n",
            "Epoch: 36, mse: 0.4225\n",
            "Epoch: 37, mse: 0.4030\n",
            "Epoch: 38, mse: 0.3831\n",
            "Epoch: 39, mse: 0.3628\n",
            "Epoch: 40, mse: 0.3422\n",
            "Epoch: 41, mse: 0.3215\n",
            "Epoch: 42, mse: 0.3009\n",
            "Epoch: 43, mse: 0.2803\n",
            "Epoch: 44, mse: 0.2600\n",
            "Epoch: 45, mse: 0.2401\n",
            "Epoch: 46, mse: 0.2206\n",
            "Epoch: 47, mse: 0.2016\n",
            "Epoch: 48, mse: 0.1834\n",
            "Epoch: 49, mse: 0.1658\n",
            "Epoch: 50, mse: 0.1491\n",
            "Epoch: 51, mse: 0.1332\n",
            "Epoch: 52, mse: 0.1182\n",
            "Epoch: 53, mse: 0.1042\n",
            "Epoch: 54, mse: 0.0912\n",
            "Epoch: 55, mse: 0.0791\n",
            "Epoch: 56, mse: 0.0681\n",
            "Epoch: 57, mse: 0.0580\n",
            "Epoch: 58, mse: 0.0489\n",
            "Epoch: 59, mse: 0.0408\n",
            "Epoch: 60, mse: 0.0336\n",
            "Epoch: 61, mse: 0.0273\n",
            "Epoch: 62, mse: 0.0218\n",
            "Epoch: 63, mse: 0.0171\n",
            "Epoch: 64, mse: 0.0132\n",
            "Epoch: 65, mse: 0.0099\n",
            "Epoch: 66, mse: 0.0072\n",
            "Epoch: 67, mse: 0.0050\n",
            "Epoch: 68, mse: 0.0033\n",
            "Epoch: 69, mse: 0.0021\n",
            "Epoch: 70, mse: 0.0011\n",
            "Epoch: 71, mse: 0.0005\n",
            "Epoch: 72, mse: 0.0002\n",
            "Epoch: 73, mse: 0.0000\n",
            "Epoch: 74, mse: 0.0000\n",
            "Epoch: 75, mse: 0.0001\n",
            "Epoch: 76, mse: 0.0003\n",
            "Epoch: 77, mse: 0.0006\n",
            "Epoch: 78, mse: 0.0008\n",
            "Epoch: 79, mse: 0.0011\n",
            "Epoch: 80, mse: 0.0013\n",
            "Epoch: 81, mse: 0.0016\n",
            "Epoch: 82, mse: 0.0018\n",
            "Epoch: 83, mse: 0.0019\n",
            "Epoch: 84, mse: 0.0020\n",
            "Epoch: 85, mse: 0.0021\n",
            "Epoch: 86, mse: 0.0021\n",
            "Epoch: 87, mse: 0.0021\n",
            "Epoch: 88, mse: 0.0020\n",
            "Epoch: 89, mse: 0.0020\n",
            "Epoch: 90, mse: 0.0018\n",
            "Epoch: 91, mse: 0.0017\n",
            "Epoch: 92, mse: 0.0016\n",
            "Epoch: 93, mse: 0.0014\n",
            "Epoch: 94, mse: 0.0013\n",
            "Epoch: 95, mse: 0.0011\n",
            "Epoch: 96, mse: 0.0010\n",
            "Epoch: 97, mse: 0.0008\n",
            "Epoch: 98, mse: 0.0007\n",
            "Epoch: 99, mse: 0.0006\n",
            "Epoch: 100, mse: 0.0005\n",
            "Epoch: 101, mse: 0.0004\n",
            "Epoch: 102, mse: 0.0003\n",
            "Epoch: 103, mse: 0.0002\n",
            "Epoch: 104, mse: 0.0001\n",
            "Epoch: 105, mse: 0.0001\n",
            "Epoch: 106, mse: 0.0001\n",
            "Epoch: 107, mse: 0.0000\n",
            "Epoch: 108, mse: 0.0000\n",
            "Epoch: 109, mse: 0.0000\n",
            "Epoch: 110, mse: 0.0000\n",
            "Epoch: 111, mse: 0.0000\n",
            "Epoch: 112, mse: 0.0000\n",
            "Epoch: 113, mse: 0.0000\n",
            "Epoch: 114, mse: 0.0000\n",
            "Epoch: 115, mse: 0.0000\n",
            "Epoch: 116, mse: 0.0000\n",
            "Epoch: 117, mse: 0.0000\n",
            "Epoch: 118, mse: 0.0000\n",
            "Epoch: 119, mse: 0.0000\n",
            "Epoch: 120, mse: 0.0000\n",
            "Epoch: 121, mse: 0.0000\n",
            "Epoch: 122, mse: 0.0000\n",
            "Epoch: 123, mse: 0.0000\n",
            "Epoch: 124, mse: 0.0000\n",
            "Epoch: 125, mse: 0.0000\n",
            "Epoch: 126, mse: 0.0000\n",
            "Epoch: 127, mse: 0.0000\n",
            "Epoch: 128, mse: 0.0000\n",
            "Epoch: 129, mse: 0.0000\n",
            "Epoch: 130, mse: 0.0000\n",
            "Epoch: 131, mse: 0.0000\n",
            "Epoch: 132, mse: 0.0000\n",
            "Epoch: 133, mse: 0.0000\n",
            "Epoch: 134, mse: 0.0000\n",
            "Epoch: 135, mse: 0.0000\n",
            "Epoch: 136, mse: 0.0000\n",
            "Epoch: 137, mse: 0.0000\n",
            "Epoch: 138, mse: 0.0000\n",
            "Epoch: 139, mse: 0.0000\n",
            "Epoch: 140, mse: 0.0000\n",
            "Epoch: 141, mse: 0.0000\n",
            "Epoch: 142, mse: 0.0000\n",
            "Epoch: 143, mse: 0.0000\n",
            "Epoch: 144, mse: 0.0000\n",
            "Epoch: 145, mse: 0.0000\n",
            "Epoch: 146, mse: 0.0000\n",
            "Epoch: 147, mse: 0.0000\n",
            "Epoch: 148, mse: 0.0000\n",
            "Epoch: 149, mse: 0.0000\n",
            "Epoch: 150, mse: 0.0000\n",
            "Epoch: 151, mse: 0.0000\n",
            "Epoch: 152, mse: 0.0000\n",
            "Epoch: 153, mse: 0.0000\n",
            "Epoch: 154, mse: 0.0000\n",
            "Epoch: 155, mse: 0.0000\n",
            "Epoch: 156, mse: 0.0000\n",
            "Epoch: 157, mse: 0.0000\n",
            "Epoch: 158, mse: 0.0000\n",
            "Epoch: 159, mse: 0.0000\n",
            "Epoch: 160, mse: 0.0000\n",
            "Epoch: 161, mse: 0.0000\n",
            "Epoch: 162, mse: 0.0000\n",
            "Epoch: 163, mse: 0.0000\n",
            "Epoch: 164, mse: 0.0000\n",
            "Epoch: 165, mse: 0.0000\n",
            "Epoch: 166, mse: 0.0000\n",
            "Epoch: 167, mse: 0.0000\n",
            "Epoch: 168, mse: 0.0000\n",
            "Epoch: 169, mse: 0.0000\n",
            "Epoch: 170, mse: 0.0000\n",
            "Epoch: 171, mse: 0.0000\n",
            "Epoch: 172, mse: 0.0000\n",
            "Epoch: 173, mse: 0.0000\n",
            "Epoch: 174, mse: 0.0000\n",
            "Epoch: 175, mse: 0.0000\n",
            "Epoch: 176, mse: 0.0000\n",
            "Epoch: 177, mse: 0.0000\n",
            "Epoch: 178, mse: 0.0000\n",
            "Epoch: 179, mse: 0.0000\n",
            "Epoch: 180, mse: 0.0000\n",
            "Epoch: 181, mse: 0.0000\n",
            "Epoch: 182, mse: 0.0000\n",
            "Epoch: 183, mse: 0.0000\n",
            "Epoch: 184, mse: 0.0000\n",
            "Epoch: 185, mse: 0.0000\n",
            "Epoch: 186, mse: 0.0000\n",
            "Epoch: 187, mse: 0.0000\n",
            "Epoch: 188, mse: 0.0000\n",
            "Epoch: 189, mse: 0.0000\n",
            "Epoch: 190, mse: 0.0000\n",
            "Epoch: 191, mse: 0.0000\n",
            "Epoch: 192, mse: 0.0000\n",
            "Epoch: 193, mse: 0.0000\n",
            "Epoch: 194, mse: 0.0000\n",
            "Epoch: 195, mse: 0.0000\n",
            "Epoch: 196, mse: 0.0000\n",
            "Epoch: 197, mse: 0.0000\n",
            "Epoch: 198, mse: 0.0000\n",
            "Epoch: 199, mse: 0.0000\n",
            "Epoch: 200, mse: 0.0000\n",
            "Epoch: 201, mse: 0.0000\n",
            "Epoch: 202, mse: 0.0000\n",
            "Epoch: 203, mse: 0.0000\n",
            "Epoch: 204, mse: 0.0000\n",
            "Epoch: 205, mse: 0.0000\n",
            "Epoch: 206, mse: 0.0000\n",
            "Epoch: 207, mse: 0.0000\n",
            "Epoch: 208, mse: 0.0000\n",
            "Epoch: 209, mse: 0.0000\n",
            "Epoch: 210, mse: 0.0000\n",
            "Epoch: 211, mse: 0.0000\n",
            "Epoch: 212, mse: 0.0000\n",
            "Epoch: 213, mse: 0.0000\n",
            "Epoch: 214, mse: 0.0000\n",
            "Epoch: 215, mse: 0.0000\n",
            "Epoch: 216, mse: 0.0000\n",
            "Epoch: 217, mse: 0.0000\n",
            "Epoch: 218, mse: 0.0000\n",
            "Epoch: 219, mse: 0.0000\n",
            "Epoch: 220, mse: 0.0000\n",
            "Epoch: 221, mse: 0.0000\n",
            "Epoch: 222, mse: 0.0000\n",
            "Epoch: 223, mse: 0.0000\n",
            "Epoch: 224, mse: 0.0000\n",
            "Epoch: 225, mse: 0.0000\n",
            "Epoch: 226, mse: 0.0000\n",
            "Epoch: 227, mse: 0.0000\n",
            "Epoch: 228, mse: 0.0000\n",
            "Epoch: 229, mse: 0.0000\n",
            "Epoch: 230, mse: 0.0000\n",
            "Epoch: 231, mse: 0.0000\n",
            "Epoch: 232, mse: 0.0000\n",
            "Epoch: 233, mse: 0.0000\n",
            "Epoch: 234, mse: 0.0000\n",
            "Epoch: 235, mse: 0.0000\n",
            "Epoch: 236, mse: 0.0000\n",
            "Epoch: 237, mse: 0.0000\n",
            "Epoch: 238, mse: 0.0000\n",
            "Epoch: 239, mse: 0.0000\n",
            "Epoch: 240, mse: 0.0000\n",
            "Epoch: 241, mse: 0.0000\n",
            "Epoch: 242, mse: 0.0000\n",
            "Epoch: 243, mse: 0.0000\n",
            "Epoch: 244, mse: 0.0000\n",
            "Epoch: 245, mse: 0.0000\n",
            "Epoch: 246, mse: 0.0000\n",
            "Epoch: 247, mse: 0.0000\n",
            "Epoch: 248, mse: 0.0000\n",
            "Epoch: 249, mse: 0.0000\n",
            "Epoch: 250, mse: 0.0000\n",
            "Epoch: 251, mse: 0.0000\n",
            "Epoch: 252, mse: 0.0000\n",
            "Epoch: 253, mse: 0.0000\n",
            "Epoch: 254, mse: 0.0000\n",
            "Epoch: 255, mse: 0.0000\n",
            "Epoch: 256, mse: 0.0000\n",
            "Epoch: 257, mse: 0.0000\n",
            "Epoch: 258, mse: 0.0000\n",
            "Epoch: 259, mse: 0.0000\n",
            "Epoch: 260, mse: 0.0000\n",
            "Epoch: 261, mse: 0.0000\n",
            "Epoch: 262, mse: 0.0000\n",
            "Epoch: 263, mse: 0.0000\n",
            "Epoch: 264, mse: 0.0000\n",
            "Epoch: 265, mse: 0.0000\n",
            "Epoch: 266, mse: 0.0000\n",
            "Epoch: 267, mse: 0.0000\n",
            "Epoch: 268, mse: 0.0000\n",
            "Epoch: 269, mse: 0.0000\n",
            "Epoch: 270, mse: 0.0000\n",
            "Epoch: 271, mse: 0.0000\n",
            "Epoch: 272, mse: 0.0000\n",
            "Epoch: 273, mse: 0.0000\n",
            "Epoch: 274, mse: 0.0000\n",
            "Epoch: 275, mse: 0.0000\n",
            "Epoch: 276, mse: 0.0000\n",
            "Epoch: 277, mse: 0.0000\n",
            "Epoch: 278, mse: 0.0000\n",
            "Epoch: 279, mse: 0.0000\n",
            "Epoch: 280, mse: 0.0000\n",
            "Epoch: 281, mse: 0.0000\n",
            "Epoch: 282, mse: 0.0000\n",
            "Epoch: 283, mse: 0.0000\n",
            "Epoch: 284, mse: 0.0000\n",
            "Epoch: 285, mse: 0.0000\n",
            "Epoch: 286, mse: 0.0000\n",
            "Epoch: 287, mse: 0.0000\n",
            "Epoch: 288, mse: 0.0000\n",
            "Epoch: 289, mse: 0.0000\n",
            "Epoch: 290, mse: 0.0000\n",
            "Epoch: 291, mse: 0.0000\n",
            "Epoch: 292, mse: 0.0000\n",
            "Epoch: 293, mse: 0.0000\n",
            "Epoch: 294, mse: 0.0000\n",
            "Epoch: 295, mse: 0.0000\n",
            "Epoch: 296, mse: 0.0000\n",
            "Epoch: 297, mse: 0.0000\n",
            "Epoch: 298, mse: 0.0000\n",
            "Epoch: 299, mse: 0.0000\n",
            "Epoch: 300, mse: 0.0000\n",
            "Epoch: 301, mse: 0.0000\n",
            "Epoch: 302, mse: 0.0000\n",
            "Epoch: 303, mse: 0.0000\n",
            "Epoch: 304, mse: 0.0000\n",
            "Epoch: 305, mse: 0.0000\n",
            "Epoch: 306, mse: 0.0000\n",
            "Epoch: 307, mse: 0.0000\n",
            "Epoch: 308, mse: 0.0000\n",
            "Epoch: 309, mse: 0.0000\n",
            "Epoch: 310, mse: 0.0000\n",
            "Epoch: 311, mse: 0.0000\n",
            "Epoch: 312, mse: 0.0000\n",
            "Epoch: 313, mse: 0.0000\n",
            "Epoch: 314, mse: 0.0000\n",
            "Epoch: 315, mse: 0.0000\n",
            "Epoch: 316, mse: 0.0000\n",
            "Epoch: 317, mse: 0.0000\n",
            "Epoch: 318, mse: 0.0000\n",
            "Epoch: 319, mse: 0.0000\n",
            "Epoch: 320, mse: 0.0000\n",
            "Epoch: 321, mse: 0.0000\n",
            "Epoch: 322, mse: 0.0000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-186-8dc2a256ef26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-182-59e043d95bde>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#x = F.dropout(x, training=self.training)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/nn/models/basic_gnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight, edge_attr)\u001b[0m\n\u001b[1;32m    173\u001b[0m                                   edge_attr=edge_attr)\n\u001b[1;32m    174\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_edge_weight\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_edge_attr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    192\u001b[0m                     \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/nn/dense/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hq3l5H9a33n",
        "outputId": "2ea83f7c-7151-4254-bfaf-73f7d4099aed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9996],\n",
              "        [0.9996],\n",
              "        [0.9996],\n",
              "        ...,\n",
              "        [0.9996],\n",
              "        [0.9996],\n",
              "        [0.9996]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ti2GNkYAbnDw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}